---
title: "ðŸ’» Week 04 - Summative assessment"
date: 16 September 2022
date-meta: 16 September 2022
author: Anton Boichenko
---

Welcome to the second summative assessment of this course! This time you will continue exploring the world of web-scrapping. We hope you will have fun completing this one, as we tried to make it as entertaining for you as possible. 

### Things to know before you start:  

1. You can find the **deadline** for this assignment on Moodle.
2. You will be granted a maximum of 15 points for the whole assignment. You will see how much each task is right next to the tasks' names. 
3. Read the instructions carefully and make sure you follow them.

## P0: Only for you 

This assignment has individual tasks for each student. You will find them on your cloud machine profile. 

ðŸŽ¯ **ACTION POINTS**

1. Go to your cloud machine user.
2. Locate the file called `summative_04.txt` and download it.

This file contains your unique assignment. 

## P1: Loving food (3 points)

ðŸŽ¯ **ACTION POINTS**

The unique instructions for this task are provided in `summative_04.txt`. Go to the file and follow the instructions for the first task. 

## P2: Keep loving food (5 points)

ðŸŽ¯ **ACTION POINTS**

1. Replicate your previous task using Selenium.
2. Additionally take the following steps **using Selenium**:

    1. Go to **Recipe collections** for whatever dish you were asked to search for in the previous task.
    2. Choose the first recipe collection, and scroll down to the button that says **Load more**.
    3. Click this button.
    4. Get to the last recipe that appeared after clicking this button. 
    5. Scrape all the information about this recipe. Structure and save it in a JSON format in the file called `Selenium_collections.json`. 

    Make sure all the steps are shown in your code. 

3. Save the code in the file called `food_Selenium` (the extension of the file will depend on the language you use). Make sure you provide your code with comments. 

## P3: Getting the news (5 points)

ðŸŽ¯ **ACTION POINTS**

1. Register for the [NYT Article Search API](https://developer.nytimes.com/docs/articlesearch-product/1/overview) and acquire an API key.
2. Explore the documentation of the API to complete further steps.
3. Extract the **titles** of articles, their **publishing dates** and **links** to them following the instructions in `summative_04.txt`. Save everything in a JSON format in the file called `NYT_articles.json`.  
4. Plot the average size of the articles (measured in the number of words) for each month in your period. 
5. Save the code in the file called `NYT_API_code` (the extension of the file will depend on the language you use). Make sure you provide your code with comments. 

## P4: Simple English (2 points)

ðŸŽ¯ **ACTION POINTS**

1. Take the first 20 articles that you have scrapped in the previous exercise. 
2. Go to [this dictionary API](https://dictionaryapi.dev/) and explore how to use it for the next tasks. 
3. Using this API, create a JSON file containing the original 20 article titles and their phonetic representations. For instance, if the title is "Data Science" your JSON record should look like this:

    ```json
    {"Data Science": "ËˆdaetÉ™ ËˆsaÉªÉ™ns"}
    ```

4. Save all the phonetic representations and the original titles in the file called `NYT_phonetic.json`.

## P5: Upload your solutions 

ðŸŽ¯ **ACTION POINTS**

1. Connect to your user on the cloud machine.
2. Create a folder called `summative04`.
3. Upload all the created files (your code and the scrapped data) to the folder.