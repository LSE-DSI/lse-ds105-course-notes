---
title: "‚úçÔ∏è Summative W05-W07"
date: 18 October 2022
date-meta: 18 October 2022
author: Anton Boichenko & Dr. Jon Cardoso-Silva
---

Welcome to the second summative assessment of this course! This time you will continue exploring the world of web-scraping. We hope you will have fun completing this one, as we tried to make it as entertaining for you as possible. 

### Things to know before you start:  

1. You can find the **deadline** for this assignment on Moodle.
2. You will be granted a maximum of 100 points for the whole assignment. You will see how much each task is right next to the tasks' names. 
3. Read the instructions carefully and make sure you follow them.

## P0: Only for you 

This assignment has individual tasks for each student. You will find them on your cloud machine profile. 

üéØ **ACTION POINTS**

1. Go to your cloud machine user.
2. Locate the file called `summative_04.txt` and download it.

This file contains your unique assignment. 

## P1: Loving food (30 points)

In this part you will be collecting data from the [BBC Good Food website](https://www.bbcgoodfood.com/). You will be collecting recipes of various dishes. 

üéØ **ACTION POINTS**

1. Write the code that executes what is asked for in Task 1 in `summative_04.txt`. 
2. Save the code in the file called `BBC_food_scrapping` (the extension of the file will depend on the language you use). Make sure you **provide your code with comments**.  

The instructions on how to submit your code and data are provided in **P4: Upload your solutions** below. 

## P2: Getting the news (50 points)

üéØ **ACTION POINTS**

1. Register for the [NYT Article Search API](https://developer.nytimes.com/docs/articlesearch-product/1/overview) and acquire an API key.
2. Explore the documentation of the API to complete further steps.
3. Extract the **titles** of articles, their **publishing dates** and **links** to them following the instructions in `summative_04.txt`.   
4. Plot the average size of the articles (measured in the number of words) for each month in your period. 
5. Save the code in the file called `NYT_API_collection` (the extension of the file will depend on the language you use). Make sure you provide your code with comments. 

## P3: Simple English (20 points)

üéØ **ACTION POINTS**

1. Take the first 20 articles that you have scrapped in the previous exercise. 
2. Go to [this dictionary API](https://dictionaryapi.dev/) and explore how to use it for the next tasks. 
3. Using this API, create a JSON file containing the original 20 article titles and their phonetic representations. For instance, if the title is "Data Science" your JSON record should look like this:

    ```json
    {"Data Science": "Ààdaet…ô Ààsa…™…ôns"}
    ```

4. Save all the phonetic representations and the original titles in the file called `NYT_phonetic.json`.

## P4: Upload your solutions 

üéØ **ACTION POINTS**

1. Connect to your user on the cloud machine.
2. Create a folder called `summative04` **on your user**.
3. Upload all the created files (**both** ayour code and the scrapped data) to the folder.