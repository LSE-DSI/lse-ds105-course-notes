[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "LSE DS105M (2022/23)",
    "section": "",
    "text": "üéØ Learning Objectives\n\nUnderstand the basic structure of data types and common data formats\nShow familiarity with international standards for common data types\nManage a typical data acquisition, cleaning, structuring, and analysis workflow using practical examples\nClean data, and diagnose common problems involved in data corruption and how to fix them\nUnderstand the concept and fundamentals of databases\nLink data from different sources\nUse the collaboration and version control system GitHub, based on the git version control system.\nMarkup Language (XML), and the Markdown format for formatting documents and web pages.\nCreate and maintain simple websites using HTML and CSS\nUse APIs to send and retrieve data from Internet sources\n\n\n\nüßëüèª‚Äçüè´ Our Team\n\nTeacher responsibleTeaching assistantsAdministrative support\n\n\n\nDr.¬†Jonathan Cardoso-Silva  Assistant Professorial Lecturer  LSE Data Science Institute Office Hours: book via StudentHub\n\n\n\nAnton Boichenko  Guest Teacher Office Hours: book via StudentHub\n\nXiaowei Gao  Guest Teacher Office Hours: book via StudentHub\n\nYijun Wang  Guest Teacher Office Hours: book via StudentHub\n\n\n\nNathaniel Ocquaye  Teaching Support and Events Officer Office: PEL 9.01 Email: DSI.UG at lse dot ac dot uk\n\nJill Beattie  Institute Coordinator Office: PEL 9.01E Tel: +44 (0) 20 7955 7759 Email: DSI.Admin at lse dot ac dot uk"
  },
  {
    "objectID": "main/assessments.html",
    "href": "main/assessments.html",
    "title": "Assessments",
    "section": "",
    "text": "This course is assessed by a mix of problem sets, group presentation and a final project. You can find the details below:"
  },
  {
    "objectID": "main/assessments.html#problem-sets-25",
    "href": "main/assessments.html#problem-sets-25",
    "title": "Assessments",
    "section": "üìù Problem Sets (25%)",
    "text": "üìù Problem Sets (25%)\n\nA mix of coding tasks and elements of self-assessment, similar to problem sets we solve in the weekly labs\nStudents have until the day before the following class to submit their response to problem sets\nSummative problem sets will be released on:\n\nWeek 03 - worth 10% of final mark\nWeek 04 - worth 15% of final mark"
  },
  {
    "objectID": "main/assessments.html#group-presentation-35",
    "href": "main/assessments.html#group-presentation-35",
    "title": "Assessments",
    "section": "üó£Ô∏è Group Presentation (35%)",
    "text": "üó£Ô∏è Group Presentation (35%)\n\nStudents will form groups prior to Reading Week (Week 06)\n\nPitch your ideas of API/datasets on Week 04\nForm the groups on Week 05\n\nGroup presentations:\n\nWeek 08 - worth 15% of final mark\nWeek 11 - worth 20% of final mark"
  },
  {
    "objectID": "main/assessments.html#final-project-40",
    "href": "main/assessments.html#final-project-40",
    "title": "Assessments",
    "section": "üéá Final Project (40%)",
    "text": "üéá Final Project (40%)\n\nEach group will have to produce a webpage of their project, using Github Markdown\nDescription of data, research questions, challenges, statistics and simple plots\nThink of it as a portfolio project!\nSubmission deadline: Lent Term\n\nExact date to be confirmed\n(end of Jan/2023 - beginning of Feb/2023)"
  },
  {
    "objectID": "main/communication.html",
    "href": "main/communication.html",
    "title": "Communication",
    "section": "",
    "text": "Find out how to talk to your peers, teaching and administrative staff during this course.\n\n\n\nMost of our ‚Äúinformal‚Äù communication and interactions will happen through Slack.\nSlack is a platform used by many companies and institutions where teams can collaborate and communicate about a specific project.\nThere will be channels dedicated to discussing each week‚Äôs content, a channel for sharing useful links and events, plus a random channel to share random stuff about data science.\n\nYou will receive an invitation to join our Slack group via e-mail. Send an e-mail to Jon (J.Cardoso-Silva at lse dot ac dot uk) if you have not received an invite by the time of the first lecture.\nCheck out the following links to understand more about this tool:\n\nSlack tutorials\nCollaborate effectively in channels\n\n\n\n\n\nIt is probably a good idea to book office hours if:\n\nyou struggled with a technical or theoretical aspect of a problem set in the previous week,\nyou have queries about careers in data science,\nyou want guidance in how to apply data science to other things you are studying outside this course.\n\nCome prepared. You only have 15 minutes.\nAsk for help sooner rather than later.\nBook slots via StudentHub up to 12 hours in advance.\n\n‚ö†Ô∏è Reserve üìß e-mail for formal requests: extensions, deferrals, etc. No need to e-mail to inform you will skip a class, for example."
  },
  {
    "objectID": "main/regulation.html",
    "href": "main/regulation.html",
    "title": "LSE DS105 | CAPIS",
    "section": "",
    "text": "This browser does not support PDFs. Please download the PDF to view it: Download PDF."
  },
  {
    "objectID": "main/syllabus.html",
    "href": "main/syllabus.html",
    "title": "LSE DS105M",
    "section": "",
    "text": "A list of what will happen every week.\nClick on each Week‚Äôs link for more information (slides, lab instructions, recommended resources, etc.).\nNote about formative assessment: besides the in-person lab exercises, we might give take-home assignments on certain weeks. Even though we do not grade these problem sets, you will get written feedback on these formative assignments.\nThis course will help you become familiarised with the most fundamental practical tools needed to gather (Weeks 02-04) and pre-process data (Weeks 05-09) and will give you some inspiration for some fundamental analysis (Weeks 10-11) to perform in your selected datasets.\nThese skills are cumulative, so practice what you learned each week and make the most of lectures, labs and our Slack group. We believe these points of contact and integration will create a fertile environment of ideas for your project.\nüí° Remember: collaboration is key to the success of a data science project!\n\n\n\n\n\n\nIntro\n\n\n\n\n\n\n\n\nüóìÔ∏è Week 01\n\n\nLecture\n\n\nIntroduction and the Data Science Toolbox üß∞\n\n\n\n\nLab\n\n\nNo class this week. (Use this time to revisit basic R or python programming)\n\n\n\n\n\nTheme: Behind the scenes\n\n\n\n\n\n\n\n\nüóìÔ∏è Week 02\n\n\nLecture\n\n\nOperating Systems, Files & The Terminal\n\n\n\n\nLab\n\n\nNavigating the command line in your own computer\n\n\n\n\n\n\n\n\n\nüóìÔ∏è Week 03\n\n\nLecture\n\n\nThe Cloud: accessing and getting data in and out.\n\n\n\n\nLab\n\n\nConnecting to the cloud via the command line\n\n\n\n\nSummative\n\n\n\n\nWorth: 10% of final marks\n\n\nProblem set involving the upload of data to the cloud.\n\n\nDeadline: day before next week‚Äôs lab\n\n\n\n\n\n\n\n\n\n\n\nüóìÔ∏è Week 04\n\n\nLecture\n\n\nThe Internet: protocols + scraping + APIs.\n\n\n\n\nLab\n\n\nWeb scraping exercise\n\n\n\n\nSummative\n\n\n\n\nWorth: 15% of final marks\n\n\nProblem set involving web scraping.\n\n\nDeadline: day before next week‚Äôs lab\n\n\n\n\n\n\nGroup project\n\n\n\n\nafter class, students pitch their ideas of preferred APIs/datasets\n\n\nthere will be a designated channel on our Slack for this\n\n\n\n\n\n\n\nTheme: Working with data\n\n\n\n\n\n\n\n\nüóìÔ∏è Week 05\n\n\nLecture\n\n\n(Re)shaping data.\n\n\n\n\nLab\n\n\nGithub & Markdown\n\n\n\n\nGroup project\n\n\n\n\nstudents form groups of 3\n\n\nstudents must submit a team contract to Moodle (not graded)\n\n\n\n\n\n\n\n\n\n\n\nüóìÔ∏è Week 06\n\n\nReading Week\n\n\n\n\n\n\n\n\n\nüóìÔ∏è Week 07\n\n\nLecture\n\n\nDataframes, databases & data normalisation.\n\n\n\n\nLab\n\n\nComputational Notebooks and DataFrames\n\n\n\n\n\n\n\n\n\nüóìÔ∏è Week 08\n\n\nLecture\n\n\nUnstructured data (text, audio & image).\n\n\n\n\nLab\n\n\nWe will have group presentations instead of a structured class this week.\n\n\n\n\nSummative\n\n\n\n\nWorth: 15% of final marks\n\n\neach group will present about their selected data.\n\n\nsee instructions for marking criteria\n\n\n\n\n\n\n\n\n\n\n\nüóìÔ∏è Week 09\n\n\nLecture\n\n\nManaging your data science workflow.\n\n\n\n\nLab\n\n\nSetting up Github for your group project & GitFlow\n\n\n\n\n\nTheme: Applications\n\n\n\n\n\n\n\n\nüóìÔ∏è Week 10\n\n\nLecture\n\n\nData viz with the grammar of graphics\n\n\n\n\nLab\n\n\nü¶∏ Super tech-support (get help with your project)\n\n\n\n\n\n\n\n\n\nüóìÔ∏è Week 11\n\n\nLecture\n\n\nSentiment analysis, topic modelling and social networks\n\n\n\n\nLab\n\n\nWe will have group presentations instead of a structured class this week\n\n\n\n\nSummative\n\n\n\n\nWorth: 20% of final marks\n\n\neach group will present about their selected data\n\n\nsee instructions for marking criteria"
  },
  {
    "objectID": "weeks/week01.html",
    "href": "weeks/week01.html",
    "title": "üóìÔ∏è Week 01 - Introduction and the Data Science Toolbox",
    "section": "",
    "text": "In this first week, we will cover what you can expect to learn from this course and the course logistics: all you need to know about the structure of the lectures, classes, assessments and how we will interact throughout this course.\nWe will also cover some of the basics: what do we mean by data science and what tools will you need to use during this course?"
  },
  {
    "objectID": "weeks/week01.html#links",
    "href": "weeks/week01.html#links",
    "title": "üóìÔ∏è Week 01 - Introduction and the Data Science Toolbox",
    "section": "Links",
    "text": "Links\n\nüë®‚Äçüè´ Lecture slides\nüîñ Appendix"
  },
  {
    "objectID": "weeks/week02.html",
    "href": "weeks/week02.html",
    "title": "üóìÔ∏è Week 02 - Operating Systems, Files & The Terminal",
    "section": "",
    "text": "This week we will look at what happens under the hoods when you give instructions to a computer.\nYou will see a brief history of Operating Systems (OS), filesystems and the Command-Line Interface (CLI) ‚Äî or the Terminal for those on macOS ‚Äî and how any of this relates to the data analysis process. We will see why this way of interacting with our computer is the most suitable for developers and how we can interact with it.\nWe will dedicate a special time to Linux and how to interact with Linux machines. This will be particularly important for next week‚Äôs topic when we learn how to access and navigate computers living in the Cloud.\nBy the end of the week, you should be able to explore the CLI and perform basic tasks such as reading files, creating directories and calling webpages."
  },
  {
    "objectID": "weeks/week02.html#links",
    "href": "weeks/week02.html#links",
    "title": "üóìÔ∏è Week 02 - Operating Systems, Files & The Terminal",
    "section": "Links",
    "text": "Links\n\nüë®‚Äçüè´ Lecture slides\nüìí Preparing for this week‚Äôs lab\nüíª Lab roadmap\nüîñ Appendix"
  },
  {
    "objectID": "weeks/week03.html",
    "href": "weeks/week03.html",
    "title": "üóìÔ∏è Week 03 - The Cloud: accessing and getting data in and out.",
    "section": "",
    "text": "You probably use iCloud, Dropbox, Google Drive or OneDrive to store some of your files but what does it feel like to enter the cloud? We will learn how these systems are setup and in our labs, we will access and interact with a computer that lives in the Amazon WebService cloud (AWS)."
  },
  {
    "objectID": "weeks/week03.html#links",
    "href": "weeks/week03.html#links",
    "title": "üóìÔ∏è Week 03 - The Cloud: accessing and getting data in and out.",
    "section": "Links",
    "text": "Links\n\nüë®‚Äçüè´ Lecture slides\nüíª Lab roadmap"
  },
  {
    "objectID": "weeks/week01/appendix.html",
    "href": "weeks/week01/appendix.html",
    "title": "üîñ Week 01 - Appendix",
    "section": "",
    "text": "We do not have classes this week. Instead, we recommend you use this time to learn or revisit the basics of a programming language (either R or Python).\nSee sections below for advice on how to do that."
  },
  {
    "objectID": "weeks/week01/appendix.html#preparing-for-the-next-week",
    "href": "weeks/week01/appendix.html#preparing-for-the-next-week",
    "title": "üîñ Week 01 - Appendix",
    "section": "üìí Preparing for the next week",
    "text": "üìí Preparing for the next week\n\nJoin the Slack group of this course (more info)\nUse this time to learn or revisit basic programming skills. Remember: later in this course, you will start working on a group project that will require some element of coding. You are free to use either R or Python."
  },
  {
    "objectID": "weeks/week01/appendix.html#recommended-resources",
    "href": "weeks/week01/appendix.html#recommended-resources",
    "title": "üîñ Week 01 - Appendix",
    "section": "üîñ Recommended Resources",
    "text": "üîñ Recommended Resources\n\nLSE Digital Skills Lab\nLSE Digital Skills Lab offers R and python workshops during Term time and they will also give DSI students access to self-paced programming courses via Dataquest.\nFollow the links below to take the pre-sessional self-paced courses:\n\nR for Data Science Pre-sessional Course 22/23\nPython for Data Science Pre-sessional Course 22/23\n\nAlso, keep an eye on the following pages for news of the in-person workshops:\n\nR workshops\nPython workshops\n\n\n\nOther resources\n\nCheckout this summer‚Äôs LSE Careers Skill Accelerator programme. Some of the self-paced courses will remain open to LSE students until the end of the year.\n\n\n\nReady to develop the key skills employers are looking for in 2022?Join this summer's LSE Careers Skills Accelerator programme to expand your skillset!‚≠êApply on CareerHub by 11.59pm, Wed 15 June for your chance to join the programme‚≠êhttps://t.co/J5sI1NRaMA\n\n‚Äî LSE Careers ((LSECareers?)) June 9, 2022"
  },
  {
    "objectID": "weeks/week01/lecture.html",
    "href": "weeks/week01/lecture.html",
    "title": "üë®‚Äçüè´ Week 01 - Slides",
    "section": "",
    "text": "Either click on the slide area below or click here to view it in fullscreen. Use your keypad to navigate the slides."
  },
  {
    "objectID": "weeks/week01/lecture.html#coffee-break-10-min",
    "href": "weeks/week01/lecture.html#coffee-break-10-min",
    "title": "üë®‚Äçüè´ Week 01 - Slides",
    "section": "‚òï Coffee Break (10 min)",
    "text": "‚òï Coffee Break (10 min)\nUse this time to chat, stretch, drink some coffee or just relax for a bit by yourself."
  },
  {
    "objectID": "weeks/week01/lecture.html#part-ii---the-data-science-toolbox-45-50-min",
    "href": "weeks/week01/lecture.html#part-ii---the-data-science-toolbox-45-50-min",
    "title": "üë®‚Äçüè´ Week 01 - Slides",
    "section": "üß∞ Part II - The Data Science Toolbox (45-50 min)",
    "text": "üß∞ Part II - The Data Science Toolbox (45-50 min)\nEither click on the slide area below or click here to view it in fullscreen. Use your keypad to navigate the slides."
  },
  {
    "objectID": "weeks/week02/appendix.html",
    "href": "weeks/week02/appendix.html",
    "title": "üîñ Week 02 - Appendix",
    "section": "",
    "text": "üìñ Some simple definitions of common computer terms\n\n\n\nA handy glossary of terms that you might encounter when learning/studying computer programming.\nSource: (Brandies and Hogg 2021)\n\n\n\n\n\n\n\nTerm\nDefinition\n\n\n\n\nAlgorithm\nThe set of rules or calculations that are performed by a computer program. Certain algorithms may be more suitable for particular datasets and may have differences in performance (e.g., in speed or accuracy).\n\n\nCentral processing unit (CPU)\nThe chip that performs the actual computation on a compute node or VM.\n\n\nCompute node\nAn individual computer that contains a number of CPUs and associated RAM.\n\n\nCore\nPart of a CPU. Single-core processors contain 1 core per CPU, meaning CPUs and cores are often interchangeable terms.\n\n\nCPU time\nThe time CPUs have spent actually processing data (often \\(\\operatorname{CPU time} \\approx \\operatorname{Walltime} \\times \\operatorname{Number of CPUs}\\)).\n\n\nDependency\nSoftware that is required by another tool or pipeline for successful execution.\n\n\nExecutable\nThe file that contains a tool/program. Some software has a single executable, while others have multiple executables for different commands/steps.\n\n\nHigh performance computer (HPC)\nA collection of connected compute nodes.\n\n\nOperating system(OS)\nThe base software that supports a computer‚Äôs basic functions. Some of the most common linux-based operating systems include those of the Debian distribution (Ubuntu) and those of the RedHat distribution (Fedora and CentOS).\n\n\nPipeline\nA pipeline is a workflow consisting of a variety of steps (commands) and/or tools that process a given set of inputs to create the desired output files.\n\n\nProgramming languages\nSpecific syntax and rules for instructing a computer to perform specific tasks. Common programming language used in bioinformatics include Bash, Python, Perl, R, C, and C++.\n\n\nRandom access memory (RAM)\nTemporarily stores all the information the CPUs require (can be accessed by all of the CPUs on the associated node or VM).\n\n\nScheduler\nManages jobs (scripts) running on shared HPC environments. Some common schedulers include SLURM, PBS, Torque, and SGE.\n\n\nScript\nA file which contains code to be executed in a single programming language.\n\n\nThread\nNumber of computations that a program can perform concurrently‚Äîdepends on the number of cores (usually 1 core = 1 thread).\n\n\nTool\nA software program that performs an analysis on an input dataset to extract meaningful outputs/information‚ÄîTool, software, and program are often used interchangeably but refer to the core components of bioinformatics pipelines.\n\n\nVM\nVirtual machine‚ÄîSimilar to a compute node as it behaves as a single computer and contains a desired number of CPUs and associated RAM (usually associated with cloud computing).\n\n\nWalltime\nThe time a program takes to run in our clock-on-the-wall time."
  },
  {
    "objectID": "weeks/week02/appendix.html#linux-the-terminal",
    "href": "weeks/week02/appendix.html#linux-the-terminal",
    "title": "üîñ Week 02 - Appendix",
    "section": "üêß Linux & the Terminal",
    "text": "üêß Linux & the Terminal\n\nThe Linux Directory Structure Explained\nThe Linux Filesystem Explained\nLearn enough command line to be dangerous"
  },
  {
    "objectID": "weeks/week02/appendix.html#text-editors",
    "href": "weeks/week02/appendix.html#text-editors",
    "title": "üîñ Week 02 - Appendix",
    "section": "üìÉ Text editors",
    "text": "üìÉ Text editors\n\nvim and Emacs jokes :)\n\n\nvim\n\nGetting started with Vim\nThe vimtutor\nA day with vimtutor\n\n\n\nEmacs\n\nA beginner‚Äôs guide to text editing with Emacs\nEmacs complete documentation"
  },
  {
    "objectID": "weeks/week02/lab.html",
    "href": "weeks/week02/lab.html",
    "title": "üíª Week 02 - Lab Roadmap (90 min)",
    "section": "",
    "text": "This week, we will learn to access and navigate your computer in a shell called bash, the most common way to access computers in the cloud (the topic of next week‚Äôs lecture and lab).\nBy default, bash is available on Unix-based operating systems (Linux and macOS) but not on Windows. Those using Windows will have to install some additional software first."
  },
  {
    "objectID": "weeks/week02/lab.html#step-1-setting-up",
    "href": "weeks/week02/lab.html#step-1-setting-up",
    "title": "üíª Week 02 - Lab Roadmap (90 min)",
    "section": "Step 1: Setting up",
    "text": "Step 1: Setting up\n\n\n\n\n Windows users\n\n\n\nSadly, Windows command line interfaces differ from those used in Unix-based operating systems (Linux and macOS). Therefore, the commands we will learn today do not apply to Windows.\nBut fear not! Recent versions of Windows have a feature called Windows Subsystem for Linux, or WSL 1, which you can use to install Linux distributions. You just have to enable it first.\nüéØ ACTION POINTS Follow Steps 1-4 of the tutorial ‚ÄúInstall Ubuntu on Wsl2 on Windows 11 with GUI Support.‚Äù\n\n\n\n macOS users\n\n\n\nüéØ ACTION POINTS\n\nOpen the terminal\nNow, to ensure you are using the bash shell, type the following and hit ENTER:\necho $SHELL\nIf you see the following message printed on the terminal screen, you are all good to move to the next step.\n/bin/bash\nIf instead, you saw the message below:\n/bin/zsh\nThis means your computer came pre-packed with a different terminal called Z Shell. Read and follow the instructions in this tutorial to change your shell to bash 2.\n\n\n\n\n Linux users\n\n\n\nYou probably already know how to get to the terminal ‚Äî typically the shortcut Ctrl+T will get you there.\nJust ensure you are running the bash shell. If not, follow the same instructions given to macOS users above."
  },
  {
    "objectID": "weeks/week02/lab.html#step-2-locating-yourself",
    "href": "weeks/week02/lab.html#step-2-locating-yourself",
    "title": "üíª Week 02 - Lab Roadmap (90 min)",
    "section": "Step 2: Locating yourself",
    "text": "Step 2: Locating yourself\nWe will follow the instructions below step by step together while answering whatever questions you might encounter along the way.\n\nOpen the bash shell using the instructions from Step 1 above\nType pwd and hit ENTER:\n pwd\nYou should get a string of text indicating the full path of where you are inside the terminal.\nAre you currently in your $HOME directory? To find out where your home directory is, use the following command:\n echo $HOME\nAre there any files/sub-directories inside the directory you are currently in? Use ls to investigate:\n ls\nor\n ls .\nAre there any hidden files?\n ls -a\nNow, let‚Äôs explore what is above your current directory:\n ls ..\nDo you get what the different dots . and .. mean 3?\nNow, more than just look at the parent directory, let‚Äôs move there:\n cd ..\nthen use the same ls commands you explored above. Did you notice anything different now?\nLet‚Äôs force ls to print the same information in a different format. Try the following command:\n ls . -lth\nWhat does the -l, -t and -h arguments mean? You can find out by looking at the ls manual:\n man ls\nUse the arrow keys in your keyboard to scroll up and down the manual. Type the character q when you are done browsing.\nNow, try to go back to the directory you were at the start of this tutorial. Hint: if you get stuck, try pwd again and compare the output you get now to the one you got the first time you used this command.\n\n\n\n\n\n\n\nSmall Hint\n\n\n\n\n\nFor your future research, if you see ‚Äú$‚Äù sign at the beginning of the code snippets, it means you are in a system shell and should type your commands in the shell.\n $ pwd"
  },
  {
    "objectID": "weeks/week02/lab.html#step-3-wandering-away-from-home",
    "href": "weeks/week02/lab.html#step-3-wandering-away-from-home",
    "title": "üíª Week 02 - Lab Roadmap (90 min)",
    "section": "Step 3: Wandering away from $HOME",
    "text": "Step 3: Wandering away from $HOME\nNow, given what we practiced, try to follow the steps below (help from colleagues is fine) and take note of your answers to the questions.\nWe will go over the solutions once everyone has finished this step.\nüéØ ACTION POINTS\n\nGo to the root of the filesystem:\n cd /\nWhat do you see with ls? What does it mean?\nWalk around freely up and down the directories and sub-directories you encounter along the way. Check the links on üîñ Week 02 Appendix - Linux and the Terminal page to understand where you are navigating.\nWhich directory(ies) under / were you not allowed to enter? Why?\nWhat is the difference between the /root directory and the root filesystem /?\nGo back $HOME"
  },
  {
    "objectID": "weeks/week02/lab.html#step-4-installing-software",
    "href": "weeks/week02/lab.html#step-4-installing-software",
    "title": "üíª Week 02 - Lab Roadmap (90 min)",
    "section": "Step 4: Installing software",
    "text": "Step 4: Installing software\n\nüí≠ How do you install apps in your computer or smart phone?\n\nIt is very likely that you just head to a software store (Play Store, Apple Store or Microsoft Store) and download apps from there. Linux has something similar, you can access and download software using the apt command. Let‚Äôs use it to download the text editor vim.\nüéØ ACTION POINTS\n\nWhenever you want to download software with apt, you have to ensure you have the most up-to-date information from the central ‚Äústore‚Äù. You can do this via the following command:\n sudo apt update\nThis command requires you to have admin rights (as root), which is why we run it with sudo 4. You might be asked to type your password.\nInstall vim:\n sudo apt install vim\nNow you can open vim:\n vim\nTo quit, press Esc, then type :q and hit ENTER. Still stuck and cannot quit vim? You are not alone."
  },
  {
    "objectID": "weeks/week02/lab.html#step-5-creating-and-editing-files-and-directories",
    "href": "weeks/week02/lab.html#step-5-creating-and-editing-files-and-directories",
    "title": "üíª Week 02 - Lab Roadmap (90 min)",
    "section": "Step 5: Creating and editing files and directories",
    "text": "Step 5: Creating and editing files and directories\nüéØ ACTION POINTS\n\nGo to your $HOME directory or a folder of your choice. Then, create and enter a directory, let‚Äôs call it DS105:\n cd $HOME\n mkdir DS105\n cd DS105\nCreate a text file and call it README.txt:\n touch README.txt\nOpen this file with vim:\n vim README.txt\nInside vim, write something to the file (your name, a verse, a sentence, whatever comes to mind)\nNow save your changes to the file. To save a file when inside vim, press Esc then type :w and hit ENTER.\nQuit vim: press Esc, then type :q and hit ENTER 5.\nPrint the content of your file with the cat command:\n cat README.txt"
  },
  {
    "objectID": "weeks/week02/lab.html#formative-assignment",
    "href": "weeks/week02/lab.html#formative-assignment",
    "title": "üíª Week 02 - Lab Roadmap (90 min)",
    "section": "Formative assignment",
    "text": "Formative assignment\nThis problem set is not graded but you will get written feedback if you submit.\nFollow the steps below and, when asked, copy your responses to the Moodle page of this assignment.\n\nP1: Identify yourself\n\nOn the terminal, type the two commands below:\n whoami\n uname -a\nTake a screenshot (how?) of your terminal and submit to Moodle, under the field identified as P1.\n\n\n\nP2: Edit a file\n\nGo to the DS105 folder you created earlier:\n cd ~/DS105\nRename the README.txt to README.md (a markdown file):\n mv README.txt README.md\nEdit the README.md file following the template below, replacing all occurrences of <> with your responses:\n# DS105\n\nName: <>\nDate: <>\nCandidate Number: <>\nDegree Program: <>\n\n## Notes\n\n- I want to learn data science because <>\nSave and quit vim.\nPrint some metadata about your file to prove you were the one editing it:\n stat README.md\nPrint the contents of your file to the terminal:\n cat README.md\nTake a screenshot (how?) of your terminal and submit to Moodle, under the field identified as P2. Make sure that both the output of stat and cat commands are visible."
  },
  {
    "objectID": "weeks/week02/lab.html#practice-at-home-vimtutor",
    "href": "weeks/week02/lab.html#practice-at-home-vimtutor",
    "title": "üíª Week 02 - Lab Roadmap (90 min)",
    "section": "Practice at home: vimtutor",
    "text": "Practice at home: vimtutor\nüéØ ACTION POINTS\n\nOpen the terminal and type:\n vimtutor\nFollow the instructions on the screen and complete the tutorial (a total of 7 short lessons).\n\nCheck out the üîñ Week 02 Appendix - üìÉ Text editors section for more info on vim."
  },
  {
    "objectID": "weeks/week02/lecture.html",
    "href": "weeks/week02/lecture.html",
    "title": "üë®‚Äçüè´ Week 02 - Slides",
    "section": "",
    "text": "Either click on the slide area below or click here to view it in fullscreen. Use your keypad to navigate the slides."
  },
  {
    "objectID": "weeks/week02/lecture.html#coffee-break-10-min",
    "href": "weeks/week02/lecture.html#coffee-break-10-min",
    "title": "üë®‚Äçüè´ Week 02 - Slides",
    "section": "‚òï Coffee Break (10 min)",
    "text": "‚òï Coffee Break (10 min)\nUse this time to chat, stretch, drink some coffee or just relax for a bit by yourself."
  },
  {
    "objectID": "weeks/week02/lecture.html#part-ii---demo-navigating-the-terminal-45-50-min",
    "href": "weeks/week02/lecture.html#part-ii---demo-navigating-the-terminal-45-50-min",
    "title": "üë®‚Äçüè´ Week 02 - Slides",
    "section": "üñ•Ô∏è Part II - Demo: Navigating the Terminal (45-50 min)",
    "text": "üñ•Ô∏è Part II - Demo: Navigating the Terminal (45-50 min)\n\nLet‚Äôs open the Terminal!\nI will show you around your PC using some basic shell commands\nA tour around vim, a file editor\nLet‚Äôs look at a few file formats\n\nTXT\nHTML\nJSON\nCSV\nScripts\nBinary files\n\n\nTo learn more about the commands shown in the demo, read (Pelz 2018, chaps. 2‚Äì3)"
  },
  {
    "objectID": "weeks/week02/prep.html",
    "href": "weeks/week02/prep.html",
    "title": "üìí Week 02 - Preparing for the lab",
    "section": "",
    "text": "Bring your laptops. Tablets are not suitable for this class.\nStudents who use Windows will have to install additional software on their laptops. We will dedicate some of our time in the lab to this, but if you want, you could try to follow Steps 1-4 of the Canonical tutorial 1 before coming to class.\nIn the lab we will practice the concepts introduced in this week‚Äôs lecture. If a concept introduced in the lecture was not clear to you, revisit the slides and bring your questions to the lab.\nBrowse the üîñ Week 02 Appendix page:\n\nskim through the blog posts and articles therein to reinforce concepts covered in the lecture,\nbookmark whatever you feel could be relevant to you in the future\n\nTry to replicate the lecture demo before coming to the lab.\n\n\n\n\n\nFootnotes\n\n\nTutorial: ‚ÄúInstall Ubuntu on Wsl2 on Windows 11 with GUI Support‚Äù‚Ü©Ô∏é"
  },
  {
    "objectID": "weeks/week03/lab.html",
    "href": "weeks/week03/lab.html",
    "title": "üíª Week 03 - Lab Roadmap (90 min)",
    "section": "",
    "text": "Last week we explored how to navigate your computer using the bash shell. Now, it is time to go beyond your machine and get to the cloud!\nAs we have seen in the lectures, accesssing the cloud opens a variety of possibilities for us as data scientists. This week we will explore some of them. Feel free to explore more on your own. We have provided you with some support resources."
  },
  {
    "objectID": "weeks/week03/lab.html#step-1-connecting-to-the-cloud",
    "href": "weeks/week03/lab.html#step-1-connecting-to-the-cloud",
    "title": "üíª Week 03 - Lab Roadmap (90 min)",
    "section": "Step 1: Connecting to the cloud",
    "text": "Step 1: Connecting to the cloud\n\n\nThe first thing we will do is we will connect to the cloud. This will be done using an SSH connection. There are differences between UNIX systems and others in the way they work with SSH. Choose the OS you are using and follow the steps to connect to the cloud.\n\n\n Windows users\n\n\n\nThere are various SSH clients that you can use for Windows. Here we explore the one called PuTTY. You will need to follow the steps below to establish an SSH connection.\nüéØ ACTION POINTS\n\nGo to this website and download the installation file.\nInstall PuTTY using the installation file.\nLaunch PuTTY.\nNavigate to the Host Name (or IP address) box and enter the host address of our machine which is ec2-18-130-96-20.eu-west-2.compute.amazonaws.com\nClick Open.\nIf you see a secrutiy alert pop up, simply click Accept.\nEnter your username and your password (which is at this point your username).\nThe first time you login, you need to give a new password for your account. Type your current password and then make a new password as instructed. Note that it may fail to update the password because the password is too simple. Try to make more complex pattern in this case. It is recommended to have at least 8 characters with the combination of letters and numbers.\n\nOnce the password is updated, the connection will be closed and you need to reopen a connection using PuTTY. If your conection has been successfull, you will see the following screen.\nINSERT IMAGE OF THE SCREEN\nViola! Now you are connected to the cloud!\n\nIf you wish to close your connection to the cloud simply write exit and hit enter.\n\n\n\n\n macOS, Linux or WSL (Windows Subsystem for Linux) users\n\n\n\nLuckily for macOS and Linux users the connection to the SSH is much simpler. You will see that following the steps below.\nüéØ ACTION POINTS\n\nOpen the terminal.\nType the following command after replacing <username> with your actual username.\n ssh <username>@ec2-18-130-96-20.eu-west-2.compute.amazonaws.com\nEnter your password (which is at this point your username).\nThe first time you login, you need to give a new password for your account. Type your current password and then make a new password as instructed. Note that it may fail to update the password because the password is too simple. Try to make more complex pattern in this case. It is recommended to have at least 8 characters with the combination of letters and numbers.\n\nViola! Now you are connected to the cloud!\n\nIf you wish to close your connection to the cloud simply write exit and hit enter."
  },
  {
    "objectID": "weeks/week03/lab.html#step-2-exploring-the-machine",
    "href": "weeks/week03/lab.html#step-2-exploring-the-machine",
    "title": "üíª Week 03 - Lab Roadmap (90 min)",
    "section": "Step 2: Exploring the machine",
    "text": "Step 2: Exploring the machine\nNow when you have connected to the cloud machine, you can explore it! Basically you are now inside a computer but it is running on a cloud server. It means that we can run the same commands as we ran locally last week.\nIf you follow the instructions below you will see that the cloud machine is very similar to your local one.\nüéØ ACTION POINTS\n\nUse the pwd and $HOME commands to understand whether you are in your home directory.\nDoes your cloud machine have any files stored? Maybe any hidden files?\nIf you forgot how to answer those questions feel free to use the materials from last week.\nCan you access the root directory of the machine? If so, what are the folders inside the root directory?\nCome back to your home directory to continue the exercises.\nIf you experience any difficulties, ask your teacher for help."
  },
  {
    "objectID": "weeks/week03/lab.html#step-3-file-management-in-the-cloud",
    "href": "weeks/week03/lab.html#step-3-file-management-in-the-cloud",
    "title": "üíª Week 03 - Lab Roadmap (90 min)",
    "section": "Step 3: File management in the cloud",
    "text": "Step 3: File management in the cloud\nNow, you can see that the cloud machine is very similar to your local one. It means that we can also create files and directories there!\nLet‚Äôs try doing it together!\nüéØ ACTION POINTS\n\nMake sure you are in you home directory using cd and pwd.\nCreate a folder called <username>_files. Make sure to replace username with your actual username.\nGo to this folder and create a file called secret_name.txt.\nSave the name of your favorite place to eat in the file. It must be kept very secret. We don‚Äôt need this place to be too crowded, do we?\nCreate another file called secret_address.txt.\nSave the address of the same place there.\n\nPerfect! Now we have two (very secret) files in our system. In the next step we will explore how to send these files to your machine."
  },
  {
    "objectID": "weeks/week03/lab.html#step-4-a-bridge-between-the-worlds",
    "href": "weeks/week03/lab.html#step-4-a-bridge-between-the-worlds",
    "title": "üíª Week 03 - Lab Roadmap (90 min)",
    "section": "Step 4: A bridge between the worlds",
    "text": "Step 4: A bridge between the worlds\nIn the first steps of this lab we have extablished a secure connection between our computer and the cloud machine. Using this channel we can not only send commands but also send and recieve files. In order to do that we will use the scp command that stands for ‚Äúsecure copy‚Äù. Follow the steps below to save the secrets files you created above to your computer.\nGenerally the scp commands work in the following way:\n scp location_1/file location_2/file\nIt means that we are copying a file from location_1 to location_2. Let‚Äôs see how it‚Äôs done with the cloud.\nüéØ ACTION POINTS\n\nExit the cloud machine using the following code:\n\n    exit \n\nTo copy the secret_name.txt file from your cloud machine use the following command. Make sure you have replaced all the <username>s with your actual username.\n scp <username>@ec2-18-130-96-20.eu-west-2.compute.amazonaws.com:/home/<username>/<username>_files/secret_name.txt .\n‚ùó Important\nWe would encourage you to pay attention to several things here:\n\nThere is a period symbol at the end of the code. This period stands for you currentl location on your local machine. You remember that the scp command takes two locations - the one we copy the file from and the one we copy the file to. A period here basically says ‚ÄúCopy it right here‚Äù.\nYou can see that the actual path to the file on your virtual machine is specified after the hostname followed by a colon. First we specify the username, then the hostname and then the path inside of the machine.\n\nMake sure the file is copied to the chosen directory.\nBut what if we wanted to copy all the files from the folder or the folder itself? For that we can avoid specifying the whole path to a concrete file and simply replace the name of the file with an asterisk:\n scp <username>@ec2-18-130-96-20.eu-west-2.compute.amazonaws.com:/home/<username>/<username>_files/* .\nThis way we copy all the files from the <username>_files folder.\nShould you wish to copy the folder itself, use the path to the folder. You will also add the -r (for recursive) option in the code as shown below.\n scp -r <username>@ec2-18-130-96-20.eu-west-2.compute.amazonaws.com:/home/<username>/<username>_files .\nMake sure both commands worked for you."
  },
  {
    "objectID": "weeks/week03/lab.html#step-5-sending-it-back",
    "href": "weeks/week03/lab.html#step-5-sending-it-back",
    "title": "üíª Week 03 - Lab Roadmap (90 min)",
    "section": "Step 5: Sending it back",
    "text": "Step 5: Sending it back\nWe have just learned how to copy files from the cloud. The last task for us today is to send files to the cloud machine.\nüéØ ACTION POINTS\n\nChoose any directory you want on your local machine and cd there.\nCreate a file called secret_dish.txt and save the name of your favorite dish there.\nü§î Stop for a second. Do you think you can gues the way to copy this file to your cloud machine using your already acquired knowledge? We hid the solution for you to experiment.\n\n\n\nSolution\n\n\nUse the code below to copy your file to the cloud machine. Make sure to replace the <username>s with your actual username.\n scp secret_dish.txt <username>@ec2-18-130-96-20.eu-west-2.compute.amazonaws.com:/home/<username>/<username>_files\n\n\n\nLog in to your virtual machine and check if the file is there."
  },
  {
    "objectID": "weeks/week03/lab.html#step-6-it-can-wait",
    "href": "weeks/week03/lab.html#step-6-it-can-wait",
    "title": "üíª Week 03 - Lab Roadmap (90 min)",
    "section": "Step 6: It can wait",
    "text": "Step 6: It can wait\nGreat job so far! You have managed to connect to the cloud machine, navigate it and even exchange files with it. Now it‚Äôs time to get to the most exciting part! Running code on the cloud! This is what you would usually use the cloud for. Imagine you need to process millions of rows of data and you computer would take ages to do that. A cloud can help here by executing it for you without taking the resources of your computer.\nLet‚Äôs do it, but before that we will learn how to do a very interesting trick.\nüéØ ACTION POINTS\n\nOpen a new bash shell window on your local machine.\nNavigate to a directory of your choice or create one.\nCreate a new file called waiting.py and include the following code inside:\nimport time\ntime.sleep(10)\n\nprint('The waiting is complete.')\nThis file launches a script that waits for 10 seconds and then prints ‚ÄòThe waiting is complete.‚Äô. You might think that it doesn‚Äôt make sense. However, let us show you something‚Ä¶\nRun this Python script in the following way:\npython waiting.py\nWhat did it do? Hopefully, exactly what was expected. It waited for 10 seconds and then printed one sentence. You might have noticed that you could not execute commands while it was running. But what if we could!\nTry running the following code:\npython waiting.py &\nDo you see the difference? Can you now run whoami or ls while we wait for the code to run?\n\nWell done! Now you have learned how to create and run Python scripts in your terminal and also do things in parallel. Shall we try it in the cloud?"
  },
  {
    "objectID": "weeks/week03/lab.html#step-7-getting-closer-to-software-engineering",
    "href": "weeks/week03/lab.html#step-7-getting-closer-to-software-engineering",
    "title": "üíª Week 03 - Lab Roadmap (90 min)",
    "section": "Step 7: Getting closer to software engineering",
    "text": "Step 7: Getting closer to software engineering\nLet‚Äôs now explore the same operations in the cloud.\nüéØ ACTION POINTS\n\nConnect to the virtual machine.\nCreat a folder called test_code.\nCreate a file called test.py or test.R depending on what language you want to use (for Python and R, respectively).\nIn the file\n\ncreate a variable called age\nassign it with your age\nmake the machine wait for 5 seconds (time.sleep(5) in Python or Sys.sleep(5) in R)\nuse print() function to print your age\n\nUse the following code to execute your script on the cloud:\n python test.py\nor\n Rscript test.R\nDoes it print your age?\nGo ahead and experiment with using the & operator. It really comes in handy if you want your cloud machine to contine running without you constantly monitoring it.\n\nYou can check out the tuttorial on how to run Python scripts ot R scripts to help you."
  },
  {
    "objectID": "weeks/week03/summative.html",
    "href": "weeks/week03/summative.html",
    "title": "üíª Week 03 - Summative assessment",
    "section": "",
    "text": "Welcome to your first summative assessment for this course! We hope you have enjoyed interacting with the cloud and are ready to put your skills to use. This summative will consist of 4 parts and will cover several areas of your cloud-related skills."
  },
  {
    "objectID": "weeks/week03/summative.html#p1-book-worms-2-points",
    "href": "weeks/week03/summative.html#p1-book-worms-2-points",
    "title": "üíª Week 03 - Summative assessment",
    "section": "P1: Book worms (2 points)",
    "text": "P1: Book worms (2 points)\nüéØ ACTION POINTS\n\nOpen the bash shell on your local machine.\nCreate a .txt file called my_fav_book.txt.\nAdd the title and the author of your favourite book to the file in the following way:\nTitle: Aristotle\n\nAuthor: Politics\nCreate a folder on your cloud machine called summative_03 and copy that .txt file to that folder. The folder should be located in the following way: /home/<username>/summative_03.\nMake sure you copy the file from your local machine to the cloud and not create an identical one straight on the cloud machine.\n\nConnect to the cloud machine.\nUsing the cloud bash shell, print the content and the metadata (feel free to look at our last week‚Äôs materials) of this file. Then, take a screenshot of the result of those commands running. Please, make sure that your username is visible in the screenshot."
  },
  {
    "objectID": "weeks/week03/summative.html#p2-run-the-code-in-the-cloud-3-points",
    "href": "weeks/week03/summative.html#p2-run-the-code-in-the-cloud-3-points",
    "title": "üíª Week 03 - Summative assessment",
    "section": "P2: Run the code in the cloud (3 points)",
    "text": "P2: Run the code in the cloud (3 points)\nüéØ ACTION POINTS\n\nGo to your cloud machine.\nCreate a Python or an R script called script.py or script.R, respectively, in the folder called summative_03.\nThe script must do the following:\n\nPrint your AWS username (the one you were provided at the beginning of the course)\nPrint the current time (you can search for ways to do that)\nWait for 10 seconds\nPrint the current time again\n\nRun the script and take a screenshot of the results of running it.\nRun the script again but this time make a tweak to your bash command that we discussed last week. The tweak should allow you to interact with your bash shell even while Python is running. To prove that it has worked, call an ls command while Python is waiting for 10 seconds in-between printing commands. Take a screenshot of the result of this code running.\nPrint the metadata of your file and take a screenshot of it."
  },
  {
    "objectID": "weeks/week03/summative.html#p3-its-time-to-search-5-points",
    "href": "weeks/week03/summative.html#p3-its-time-to-search-5-points",
    "title": "üíª Week 03 - Summative assessment",
    "section": "P3: It‚Äôs time to search (5 points)",
    "text": "P3: It‚Äôs time to search (5 points)\nüéØ ACTION POINTS\n\nGo to your cloud machine.\nNavigate to the /home/admin/week_03 directory. You will see a lot of .md files there. One of them is yours.\nFind the file that was created for you.\nThis part is a bit tricky. What you need to do is to go through these files one by one and find the one that has your LSE ID in it.\nCopy this file to the summative_03 folder on your user within the cloud machine.\nChange the permissions on this file for you to be able to edit it.\nEdit the file and answer the questions in it.\nPrint the content of the file and the file‚Äôs metadata. Take a screenshot of both."
  },
  {
    "objectID": "weeks/week03/summative.html#p4-submit-no-points",
    "href": "weeks/week03/summative.html#p4-submit-no-points",
    "title": "üíª Week 03 - Summative assessment",
    "section": "P4: Submit (no points)",
    "text": "P4: Submit (no points)\nUpload your screenshots to Moodle togther with the infromation required."
  },
  {
    "objectID": "weeks/week04/lab.html",
    "href": "weeks/week04/lab.html",
    "title": "üíª Week 04 - Lab Roadmap (90 min)",
    "section": "",
    "text": "This week it is time for you to go beyond your own machine and even beyond a cloud machine and visit the Internet!\nIn today‚Äôs lab we will get familiar with web-scraping, a notion that describes the practices of automated data acquisition from the Internet. This lab is split into three parts: classic HTML scraping, scraping using APIs and scraping using Selenium. These skills are not only essential for your data collection for this course but will be exceptionally useful for you in your own research."
  },
  {
    "objectID": "weeks/week04/lab.html#part-1-exploring-lse",
    "href": "weeks/week04/lab.html#part-1-exploring-lse",
    "title": "üíª Week 04 - Lab Roadmap (90 min)",
    "section": "Part 1: Exploring LSE",
    "text": "Part 1: Exploring LSE\n\n\nOur first task is to learn a bit more about LSE. LSE has many departments. One of them is the Department of Methodology. The department has people with experience in various methods. Today we will create a list of all the methods the Methodology staff has.\nMain task: create a list of all the key areas of expertise that the Department of Methodology has.\nü§î Stop and think. Before you start following the instructions. Can you think of a way to acquire this information using the LSE website?\nLet‚Äôs explore one of the possible ways to do that. We do not provide you with code straight away as we assume that you will be guided during the lab. However, the code is given to you after the action points.\nüéØ ACTION POINTS\n\nGo to the Department of Methodology People page and navigate to Academic Staff.\nInspect the page to find the HTML element that allows you to get to the person‚Äôs individual page.\nUsing the language of your choice create a list of the links to the individual pages of all the Academic Staff Members.\nUsing the saved links, go through all of them and extract the Key Areas of Expertise for all the Staff Members.\nCreate one list to store all the Areas of Expertise and delete duplicates from there.\n\nDo you find any areas that are relevant for you?\nOptional task\nThink of a way to scrape and store these data in a way that would link Academic Staff Members to their Key Areas of Expertise.\n\nSolution Code\n\n\n Python users\n\n# import the required libraries\nimport requests\nfrom bs4 import BeautifulSoup\n\n# sending a request to the site\nresponse_html = requests.get(\"https://www.lse.ac.uk/Methodology/People\")\n\n# parsing page\"s content\nsoup = BeautifulSoup(response_html.text)\n\n# empty list to store links to pages\nlinks_to_staff = []\n\n# subsetting only for academic staff\nall_ac_staff = soup.find_all(\"div\", attrs={\"class\":\"accordion__panel\"})[0].find_all(\"a\", attrs={\"class\":\"sys_0 sys_t0\"})\n\n# iterating through all of the staff saving the links\nfor person in all_ac_staff:\n\n    # extracting a link\n    link = person.get(\"href\")\n    \n    link = \"https://www.lse.ac.uk\" + link\n\n    links_to_staff.append(link)\n\n# empy list to store key areas of experience \nkey_exp = []\n\n# iterating through all staff members' pages\nfor link in links_to_staff:\n    \n    # extracting their research interests\n    response_html = requests.get(link)\n    \n    soup = BeautifulSoup(response_html.text)\n    \n    exp = soup.find_all(\"div\", attrs={\"class\":\"peopleContact__address\"})[-1].get_text()\n    \n    key_exp.append(exp)\n    \n# cleaning up the string to create a list of all areas\nfinal_list = \",\".join(key_exp).replace(\".\", \" \").replace(\",\", \";\").replace(\"; \", \";\").split(\";\")\n\n\n\n R users\n\n# import required packages\nlibrary(rvest)\nlibrary(magrittr)\nlibrary(stringi)\n\n# read the content of the site\nurl <- \"https://www.lse.ac.uk/Methodology/People\"\nhtml <- read_html(url)\n\n# extract the elements related to academic staff only\nhtml_nodes(html, css = \".accordion__panel\")[1] %>%\n  html_nodes(css = \".sys_0 sys_t0\")\n\n# extract links to individual pages\nlinks_to_staff <- html_nodes(html, css = \".accordion__panel\")[1] %>%\n  html_nodes(css = \"a\") %>%\n  html_attr(\"href\")\n\n# add the base URL to the link\nlinks_to_staff <- paste(\"https://www.lse.ac.uk\", links_to_staff, sep = \"\")\n\n# write a function that extracts areas of experience from each page\nget_expert <- function(link) {\n  url <- link\n  html <- read_html(url)\n  \n  html_nodes(html, css = \".peopleContact__address\") %>%\n    tail(1) %>%\n    html_text()\n  \n}\n\n# apply the function to all pages\nresult <- sapply(links_to_staff, get_expert)\n\n# clean up the areas of expertise\nres <- paste(result, collapse = \";\") %>%\n  stri_replace_all_fixed(\".\", \" \") %>%\n  stri_replace_all_fixed(\",\", \";\") %>%\n  stri_replace_all_fixed(\"; \", \";\")\n\n# create a list of all areas\nfinal_list <- stri_split_fixed(res, \";\")[[1]]"
  },
  {
    "objectID": "weeks/week04/lab.html#part-2-buying-tickets",
    "href": "weeks/week04/lab.html#part-2-buying-tickets",
    "title": "üíª Week 04 - Lab Roadmap (90 min)",
    "section": "Part 2: Buying tickets",
    "text": "Part 2: Buying tickets\nAfter completing the last exercise you might think ‚ÄúWell, yeah, it is useful for my academic endeavours, but not for my day-to-day life.‚Äù. Let us show you how you can solve your problems with it!\nIt turns out that TicketMaster (one of the biggest websites that sells tickets) has its own API. It means that you can automate your ticket search if you wanted to! Let‚Äôs explore this together.\nWe do not provide you with code straight away, however, you will find the solutions below.\nüéØ ACTION POINTS\n\nGo to https://developer.ticketmaster.com/ and register an account. You will only need an email address.\nAcquire an API token using your new account. It will be called a Consumer Key in your apps‚Äô information.\nUsing the documentation find all the music events happening in London.\nHow many events have you found?\nDo you think it‚Äôs all the events happening in London?\nIs there a way to show more events?\n\nLet‚Äôs make our search a bit more narrow. Let‚Äôs imagine you are coming back from holidays on the 15th of October. Can you find Rock music events in London that are happening after that date? What if you wanted an event that you can get to for less than 30 pounds? Can you find one for yourself?\nGo ahead and try to find London events related to data and data science. Are there any? Extend your search and try again.\nWhat about family-friendly events in London? Are there any?\n\n\nSolution Code\n\n\n Python users\n\nAll the tasks above are solved with the same API URL. Here we will show the base code and mainly the parameters that yield the desired results.\nTask 3\n# import the required libraries\nimport requests\n\n# saving your API key\napi_key = \"YOUR_API_KEY\"\n\n# setting up the API query parameters (they will be changing)\nparams = {\"classificationName\": \"music\",\n          \"countryCode\": \"GB\",\n          \"city\": \"London\",\n          \"apikey\": api_key}\n\n# sending a request to the API\nresponse = requests.get(\"https://app.ticketmaster.com/discovery/v2/events.json\",\n                        params=params)\n\n# parse the response\nresp_json = response.json()\n\n# extract the events\nresp_json[\"_embedded\"][\"events\"]\nNext, we will be only providing the query parameters.\nTask 3 (extending search)\n# setting up the API query parameters (they will be changing)\nparams = {\"classificationName\": \"music\",\n          \"countryCode\": \"GB\",\n          \"city\": \"London\",\n          \"size\": 200, # feel free to change this number\n          \"page\": 1, # we add pages here to show that you can get more results if needed\n          \"apikey\": api_key}\nTask 4\n# setting up the API query parameters (they will be changing)\nparams = {\"classificationName\": \"music\",\n          \"countryCode\": \"GB\",\n          \"city\": \"London\",\n          \"genre_name\":\"Rock\",\n          \"startDateTime\":\"2022-10-15T00:00:00Z\",\n          \"size\": 200, # feel free to change this number\n          \"page\": 1, # we add pages here to show that you can get more results if needed\n          \"apikey\": api_key}\nThis API does not have a price parameter, so you would need to filter the JSON manually.\nTask 5\n# setting up the API query parameters (they will be changing)\nparams = {\"countryCode\": \"GB\",\n          \"city\": \"London\",\n          \"keyword\":\"data\",\n          \"size\": 200, # feel free to change this number\n          \"page\": 1, # we add pages here to show that you can get more results if needed\n          \"apikey\": api_key}\n\n# or\n\nparams = {\"keyword\":\"data\",\n          \"size\": 200, \n          \"page\": 1,\n          \"apikey\": api_key}\nTask 6\n# setting up the API query parameters (they will be changing)\nparams = {\"countryCode\": \"GB\",\n          \"city\": \"London\",\n          \"includeFamily\":\"only\",\n          \"size\": 200, # feel free to change this number\n          \"page\": 1, # we add pages here to show that you can get more results if needed\n          \"apikey\": api_key}\n\n\n\n R users\n\nAll the tasks above are solved with the same API URL. Here we will show the base code and mainly the parameters that yield the desired results.\nTask 3\n# importing required packages\nlibrary(\"httr\")\nlibrary(\"jsonlite\")\n\n# saving your API key\napi_key <- \"ErOQNylYMIv9wqPLWsezUdByUjftJIa6\"\n\n# setting up the base URL and parameters\nbase_url <- \"https://app.ticketmaster.com/discovery/v2/events.json\"\n\n# sending a request\nresponse <- GET(base_url, query = list(\"classificationName\" = \"music\",\n          \"countryCode\" = \"GB\",\n          \"city\" = \"London\",\n          \"apikey\" = api_key))\n\n# parse the response\njson <- content(response, \"parsed\")\nNext, we will be only providing the query parameters.\nTask 3 (extending search)\n# sending a request\nresponse <- GET(base_url, query = list(\"classificationName\" = \"music\",\n          \"countryCode\" = \"GB\",\n          \"city\" = \"London\",\n          \"size\" = 200, \n          \"page\" = 1,\n          \"apikey\" = api_key))\nTask 4\n# sending a request\nresponse <- GET(base_url, query = list(\"classificationName\" = \"music\",\n          \"countryCode\" = \"GB\",\n          \"city\" = \"London\",\n          \"genre_name\" = \"Rock\",\n          \"startDateTime\" = \"2022-10-15T00:00:00Z\",\n          \"size\" = 200, # feel free to change this number\n          \"page\" = 1, # we add pages here to show that you can get more results if needed\n          \"apikey\" = api_key))\nThis API does not have a price parameter, so you would need to filter the JSON manually.\nTask 5\n# sending a request\nresponse <- GET(base_url, query = list(\n          \"countryCode\" = \"GB\",\n          \"city\" = \"London\",\n          \"keyword\" = \"data\",\n          \"size\" = 200, # feel free to change this number\n          \"page\" = 1, # we add pages here to show that you can get more results if needed\n          \"apikey\" = api_key))\n\n# or\n\nresponse <- GET(base_url, query = list(\n          \"keyword\" = \"data\",\n          \"size\" = 200, # feel free to change this number\n          \"page\" = 1, # we add pages here to show that you can get more results if needed\n          \"apikey\" = api_key))\nTask 6\n# sending a request\nresponse <- GET(base_url, query = list(\n          \"countryCode\" = \"GB\",\n          \"city\" = \"London\",\n          \"includeFamily\" = \"only\",\n          \"size\" = 200, # feel free to change this number\n          \"page\" = 1, # we add pages here to show that you can get more results if needed\n          \"apikey\" = api_key))"
  },
  {
    "objectID": "weeks/week04/lab.html#part-3-searching-for-data-events",
    "href": "weeks/week04/lab.html#part-3-searching-for-data-events",
    "title": "üíª Week 04 - Lab Roadmap (90 min)",
    "section": "Part 3: Searching for Data events",
    "text": "Part 3: Searching for Data events\nWe have now explored one of the key methods of web scraping. However, we haven‚Äôt yet talked about the scenarios where we need to interact with a website to acquire information. This can be done with Selenium. Selenium can automatically interact with websites. Let‚Äôs see how it works.\nWe haven‚Äôt found a lot of events about data on TicketMaster. Maybe we can use another platform?\nüéØ ACTION POINTS\n\nIf you are using Python, make sure you have Google Chrome installed and chromdriver downloaded to the folder you know a path to.\nIf you are using R, make sure you have Mozilla Firefox installed.\nUsing Selenium go to the London events page on Eventbrite.\nNavigate to the search box and enter ‚Äúdata‚Äù using Selenium.\nHit enter using Selenium.\nParse the number of pages of such events from below the page.\nFind a way to go to the next page.\nWrite a loop that will go through the next 10 pages and print the date and time of the first event on the page.\n\n\nSolution Code\n\n\n Python users\n\nWe will present the whole sequence of steps here in one code.\n# import the required libraries\nfrom selenium import webdriver\nfrom selenium.webdriver import Chrome\nimport time\n\n# here you specify the Path to chromedriver\ndriver_path = \"/chromedriver_PATH\"\n\n# launching the browser \ndriver = Chrome(driver_path) \n\n# saving the link\nlink = \"https://www.eventbrite.co.uk/d/united-kingdom--london/events/\"\n\n# navigating to the page\ndriver.get(link)\n\n# navigating to the search box\nsearch = driver.find_element(\"css selector\", \"\"\"#global-header > div \n> div.consumer-header__content.consumer-header__desktop.eds-show-up-md \n> div.consumer-header__search > button > div > div > div > div\"\"\")\n\n# clicking on the search box\nsearch.click()\n\n# navigating to the search box\ninputElement = driver.find_element(\"css selector\", \"#search-autocomplete-input\")\n\n# inputting \"data\" into the search box\ninputElement.send_keys('data')\n\n# importing common keys\nfrom selenium.webdriver.common.keys import Keys\n\n# asking Selenium to hit enter\ninputElement.send_keys(Keys.ENTER)\n\n# extracting the number of pages\nn_pages_el = driver.find_element(\"css selector\", \"\"\"#root > div > div.eds-structure__body > div > div > div > div.eds-fixed-bottom-bar-layout__content \n> div > main > div > div > section.search-base-screen__search-panel\n> footer > div > div > ul > li.eds-pagination__navigation-minimal.eds-l-mar-hor-3\"\"\")\nprint(n_pages_el.text)\n\n# importing time to wait until the page loads\nimport time \n\nfor i in range(10):\n    \n    # saving the path to the first date on the page\n    first_date = driver.find_element(\"xpath\", \"\"\"//*[@id=\"root\"]/div/div[2]/div/div/div/div[1]/div/main/div/div/section[1]/\n    div[1]/div/ul/li[1]/div/div/div[1]/div/div/div/article/div[2]/div/div/div[1]/div\"\"\")\n\n    print(first_date.text)\n    \n    # saving the path to the next page button\n    next_page = driver.find_element(\"css selector\", \"\"\"#chevron-right-chunky_svg__eds-icon--chevron-right-chunky_svg\"\"\")\n    \n    # clicking for next page\n    next_page.click()\n    \n    # wait for 2 seconds\n    time.sleep(2)\n\n\n# clode the driver\ndriver.close()\n\n\n\n R users\n\nWe will present the whole sequence of steps here in one code.\n# import selenium\nlibrary(\"RSelenium\")\n\n# launching the browser \nrD<- rsDriver(browser=c(\"firefox\"))\ndriver <- rD$client\n\n# navigating to the page\nurl <- \"https://www.eventbrite.co.uk/d/united-kingdom--london/events/\"\ndriver$navigate(url)\n\n# navigating to the search box\nsearch <- driver$findElement(using = \"css selector\", value = '#global-header > div \n> div.consumer-header__content.consumer-header__desktop.eds-show-up-md \n> div.consumer-header__search > button > div > div > div > div')\n\n# clicking on the search box\nsearch$clickElement()\n\n# navigating to the search box\nsearch_field <- driver$findElement(using = \"css selector\", value = '#search-autocomplete-input')\n\n# inputting \"data\" into the search box\nsearch_field$sendKeysToElement(list(\"data\"))\n\n# asking Selenium to hit enter\npage_body <- driver$findElement(\"css\", \"body\")\npage_body$sendKeysToElement(list(key = \"enter\"))\n\n# extracting the number of pages\nn_pages <- driver$findElement(using = \"css selector\",\n                                       value = '#root > div > div.eds-structure__body > div > div > div >     \n                                       div.eds-fixed-bottom-bar-layout__content \n                                      > div > main > div > div > section.search-base-screen__search-panel\n                                      > footer > div > div > ul > li.eds-pagination__navigation-minimal.eds-l-mar-hor-3')\nn_pages <- n_pages$getElementText()[[1]]\nprint(n_pages)\n\n\nfor (i in 1:10) {\n    \n  # saving the path to the first date on the page\n  first_date <- driver$findElement(using = \"css selector\", value = \".search-main-content__events-list > li:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(2) > div:nth-child(1) > div:nth-child(2) > div:nth-child(1) > article:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(2)\")\n\n  print(first_date$getElementText()[[1]])\n  \n  # saving the path to the next page button\n  next_page <- driver$findElement(using = \"css selector\", value = '#chevron-right-chunky_svg__eds-icon--chevron-right-chunky_svg')\n  \n  # clicking for next page\n  next_page$clickElement()\n  \n  # wait for 2 seconds\n  Sys.sleep(2)\n  \n}"
  },
  {
    "objectID": "weeks/week04/summative.html",
    "href": "weeks/week04/summative.html",
    "title": "üíª Week 04 - Summative assessment",
    "section": "",
    "text": "Welcome to the second summative assessment of this course! This time you will continue exploring the world of web-scraping. We hope you will have fun completing this one, as we tried to make it as entertaining for you as possible."
  },
  {
    "objectID": "weeks/week04/summative.html#p0-only-for-you",
    "href": "weeks/week04/summative.html#p0-only-for-you",
    "title": "üíª Week 04 - Summative assessment",
    "section": "P0: Only for you",
    "text": "P0: Only for you\nThis assignment has individual tasks for each student. You will find them on your cloud machine profile.\nüéØ ACTION POINTS\n\nGo to your cloud machine user.\nLocate the file called summative_04.txt and download it.\n\nThis file contains your unique assignment."
  },
  {
    "objectID": "weeks/week04/summative.html#p1-loving-food-3-points",
    "href": "weeks/week04/summative.html#p1-loving-food-3-points",
    "title": "üíª Week 04 - Summative assessment",
    "section": "P1: Loving food (3 points)",
    "text": "P1: Loving food (3 points)\nüéØ ACTION POINTS\nThe unique instructions for this task are provided in summative_04.txt. Go to the file and follow the instructions for the first task."
  },
  {
    "objectID": "weeks/week04/summative.html#p2-keep-loving-food-5-points",
    "href": "weeks/week04/summative.html#p2-keep-loving-food-5-points",
    "title": "üíª Week 04 - Summative assessment",
    "section": "P2: Keep loving food (5 points)",
    "text": "P2: Keep loving food (5 points)\nüéØ ACTION POINTS\n\nReplicate your previous task using Selenium.\nAdditionally, take the following steps using Selenium:\n\nGo to Recipe collections for whatever dish you were asked to search for in the previous task.\nChoose the first recipe collection, and scroll down to the button that says Load more.\nClick this button.\nGet to the last recipe that appeared after clicking this button.\nScrape all the information about this recipe. Structure and save it in a JSON format in the file called Selenium_collections.json.\n\nMake sure all the steps are shown in your code.\nSave the code in the file called food_Selenium (the extension of the file will depend on the language you use). Make sure you provide your code with comments."
  },
  {
    "objectID": "weeks/week04/summative.html#p3-getting-the-news-5-points",
    "href": "weeks/week04/summative.html#p3-getting-the-news-5-points",
    "title": "üíª Week 04 - Summative assessment",
    "section": "P3: Getting the news (5 points)",
    "text": "P3: Getting the news (5 points)\nüéØ ACTION POINTS\n\nRegister for the NYT Article Search API and acquire an API key.\nExplore the documentation of the API to complete further steps.\nExtract the titles of articles, their publishing dates and links to them following the instructions in summative_04.txt. Save everything in a JSON format in the file called NYT_articles.json.\n\nPlot the average size of the articles (measured in the number of words) for each month in your period.\nSave the code in the file called NYT_API_code (the extension of the file will depend on the language you use). Make sure you provide your code with comments."
  },
  {
    "objectID": "weeks/week04/summative.html#p4-simple-english-2-points",
    "href": "weeks/week04/summative.html#p4-simple-english-2-points",
    "title": "üíª Week 04 - Summative assessment",
    "section": "P4: Simple English (2 points)",
    "text": "P4: Simple English (2 points)\nüéØ ACTION POINTS\n\nTake the first 20 articles that you have scrapped in the previous exercise.\nGo to this dictionary API and explore how to use it for the next tasks.\nUsing this API, create a JSON file containing the original 20 article titles and their phonetic representations. For instance, if the title is ‚ÄúData Science‚Äù your JSON record should look like this:\n{\"Data Science\": \"Ààdaet…ô Ààsa…™…ôns\"}\nSave all the phonetic representations and the original titles in the file called NYT_phonetic.json."
  },
  {
    "objectID": "weeks/week04/summative.html#p5-upload-your-solutions",
    "href": "weeks/week04/summative.html#p5-upload-your-solutions",
    "title": "üíª Week 04 - Summative assessment",
    "section": "P5: Upload your solutions",
    "text": "P5: Upload your solutions\nüéØ ACTION POINTS\n\nConnect to your user on the cloud machine.\nCreate a folder called summative04.\nUpload all the created files (your code and the scrapped data) to the folder."
  },
  {
    "objectID": "slides/week01_slides_part1.html#the-data-science-institute",
    "href": "slides/week01_slides_part1.html#the-data-science-institute",
    "title": "DS105 Data for Data Science",
    "section": "The Data Science Institute",
    "text": "The Data Science Institute\n\n\n\n\n\nThis course is offered by the LSE Data Science Institute (DSI).\nDSI is the hub for LSE‚Äôs interdisciplinary collaboration in data science\n\n\n\n\nSign up for DSI events at lse.ac.uk/DSI/Events"
  },
  {
    "objectID": "slides/week01_slides_part1.html#the-data-science-institute-1",
    "href": "slides/week01_slides_part1.html#the-data-science-institute-1",
    "title": "DS105 Data for Data Science",
    "section": "The Data Science Institute",
    "text": "The Data Science Institute\n\n\n\n\nActivities of interest to you:\n\nCIVICA Seminar Series\nCareers in Data Science\nSocial events\nIndustry ‚Äúfield trips‚Äù\nSummer projects\n\n\n\n\nSign up for DSI events at lse.ac.uk/DSI/Events"
  },
  {
    "objectID": "slides/week01_slides_part1.html#our-courses",
    "href": "slides/week01_slides_part1.html#our-courses",
    "title": "DS105 Data for Data Science",
    "section": "Our courses",
    "text": "Our courses\nDSI offer accessible introductions to Data Science:\n\n\nDS101\nFundamentals of  Data Science\nüéØ Focus:  theoretical concepts of data science\nüìÇ How:  reflections through reading and writing\n\nDS105\nData for  Data Scientists\nüéØ Focus: collection and handling of real data\nüìÇ How: hands-on coding exercises and a group project\n\nDS202\nData Science for  Social Scientists\nüéØ Focus: fundamental machine learning algorithms\nüìÇ How: practical use of ML techniques and metrics"
  },
  {
    "objectID": "slides/week01_slides_part1.html#your-lecturer",
    "href": "slides/week01_slides_part1.html#your-lecturer",
    "title": "DS105 Data for Data Science",
    "section": "Your lecturer",
    "text": "Your lecturer\n\n\n\n\n\n \nDr.¬†Jonathan Cardoso-Silva\n\nPhD in Computer Science\nBackground: Computer Science,Engineering,Data Science\nResearch:\n\nNetworks\nOptimisation\nMachine Learning applications\nData Science Workflow"
  },
  {
    "objectID": "slides/week01_slides_part1.html#teaching-assistants",
    "href": "slides/week01_slides_part1.html#teaching-assistants",
    "title": "DS105 Data for Data Science",
    "section": "Teaching Assistants",
    "text": "Teaching Assistants\n\n\n\nAnton Boichenko  Guest Teacher Developer at Decoded   \n\n\nXiaowei Gao  Guest Teacher PhD Student at KCL in Health Informatics  \n\n\nYijun Wang  Guest Teacher PhD Student at UCL Centre for Advanced Spatial Analysis"
  },
  {
    "objectID": "slides/week01_slides_part1.html#who-are-you",
    "href": "slides/week01_slides_part1.html#who-are-you",
    "title": "DS105 Data for Data Science",
    "section": "Who are you",
    "text": "Who are you\n\n\n\n\n\nProgramme\nFreq\n\n\n\n\nBSc in Economics\n11\n\n\nBSc in Politics and Data Science\n5\n\n\nBSc in Politics and Economics\n4\n\n\nGeneral Course\n4\n\n\nBSc in Philosophy and Economics\n2\n\n\nBSc in International Social and Public Policy with Politics\n1\n\n\nBSc in Mathematics, Statistics and Business\n1\n\n\nBSc in Philosophy, Logic and Scientific Method\n1\n\n\nBSc in Philosophy, Politics and Economics\n1\n\n\nBSc in Politics\n1\n\n\n\n\n\n\nSource: LSE For You. Last Updated: 27 September 2022"
  },
  {
    "objectID": "slides/week01_slides_part1.html#learning-objectives-cont.",
    "href": "slides/week01_slides_part1.html#learning-objectives-cont.",
    "title": "DS105 Data for Data Science",
    "section": "Learning Objectives (cont.)",
    "text": "Learning Objectives (cont.)\nThe course will also cover:\n\n\nworkflow management of individual and collaborative data science project\nsetup and tools for typical data pre-processing (data transformation and data cleaning)\n\nfrequently the starting point and most time-consuming part of any data science project."
  },
  {
    "objectID": "slides/week01_slides_part1.html#syllabus",
    "href": "slides/week01_slides_part1.html#syllabus",
    "title": "DS105 Data for Data Science",
    "section": "Syllabus",
    "text": "Syllabus\n\n\n\n\n\n\n\nIntro\n\n\n\n\n\n¬†¬†¬†¬†Introduction and key tools for data scientists\nWeek 01\n\n\nBehind the scenes\n\n\n\n¬†¬†¬†¬†The Terminal: navigating the command line ¬†¬†¬†¬†The Cloud: accessing and getting data in and out ¬†¬†¬†¬†The Internet: protocols + scrapping + APIs\nWeek 02  Week 03  Week 04\n\n\nWorking with data\n\n\n\n¬†¬†¬†¬†The nature and shape of data¬†¬†¬†¬†Tabular data: dataframes and databases¬†¬†¬†¬†Unstructured data (text, audio & image)¬†¬†¬†¬†Text as data, regex and sentiment analysis\nWeek 05  Week 07  Week 08 Week 09\n\n\nApplications\n\n\n\n¬†¬†¬†¬†Topic modelling & document similarities¬†¬†¬†¬†Data viz with the grammar of graphics\nWeek 10  Week 11"
  },
  {
    "objectID": "slides/week01_slides_part1.html#structure-of-lectures",
    "href": "slides/week01_slides_part1.html#structure-of-lectures",
    "title": "DS105 Data for Data Science",
    "section": "Structure of lectures üë®üèª‚Äçüè´",
    "text": "Structure of lectures üë®üèª‚Äçüè´\nOur lectures will be split in two parts:\n\n\nPart I (~ 50 min): Traditional exposition of theoretical content\nbreak (~ 10 min): Grab coffee ‚òï or relax üßò\nPart II (~ 50 min): Live demo\n\nTypically, demonstration of terminal usage or Jupyter notebooks\nFeel free to follow along in your own laptops."
  },
  {
    "objectID": "slides/week01_slides_part1.html#structure-of-classes",
    "href": "slides/week01_slides_part1.html#structure-of-classes",
    "title": "DS105 Data for Data Science",
    "section": "Structure of classes üë©‚Äçüíª",
    "text": "Structure of classes üë©‚Äçüíª\n\n\nStudents will work on weekly, structured problem sets in the staff-led class sessions.\nTips to get the most of classes:\n\nBring your own laptops üíª (most tablets are not suitable for programming)\nRead the recommended reading prior to the class\nAttempt to replicate the examples demonstrated in the live demo during the lecture"
  },
  {
    "objectID": "slides/week01_slides_part1.html#class-groups",
    "href": "slides/week01_slides_part1.html#class-groups",
    "title": "DS105 Data for Data Science",
    "section": "Class groups",
    "text": "Class groups"
  },
  {
    "objectID": "slides/week01_slides_part1.html#class-groups-1",
    "href": "slides/week01_slides_part1.html#class-groups-1",
    "title": "DS105 Data for Data Science",
    "section": "Class groups",
    "text": "Class groups\n\n\n\nGroup 01\n\nüìÜ Fridays\n‚åö 09:00 ‚Äî 10:30\nüìç 32L.G.06\n\n\nGroup 02\n\nüìÜ Fridays\n‚åö 12:00 ‚Äî 13:30\nüìç NAB.LG.03\n\n\nGroup 03\n\nüìÜ Fridays\n‚åö 16:00 ‚Äî 17:30\nüìç KSW.1.02\n\n\n\n\nüó∫Ô∏è Check LSE campus map"
  },
  {
    "objectID": "slides/week01_slides_part1.html#assessments",
    "href": "slides/week01_slides_part1.html#assessments",
    "title": "DS105 Data for Data Science",
    "section": "Assessments üìî",
    "text": "Assessments üìî\nThe breakdown of assessment for this course will be as follows:"
  },
  {
    "objectID": "slides/week01_slides_part1.html#assessments---problem-sets-25",
    "href": "slides/week01_slides_part1.html#assessments---problem-sets-25",
    "title": "DS105 Data for Data Science",
    "section": "Assessments - Problem sets (25%)",
    "text": "Assessments - Problem sets (25%)\n\n\nThese will involve a mix of coding tasks and elements of self-assessment (similar to problem sets we will solve in the labs)\nYou will have until the day before the following class to submit your response\nSummative problem sets will be released on:\n\nWeek 03 - worth 10% of final mark\nWeek 04 - worth 15% of final mark"
  },
  {
    "objectID": "slides/week01_slides_part1.html#assessments---group-presentations-35",
    "href": "slides/week01_slides_part1.html#assessments---group-presentations-35",
    "title": "DS105 Data for Data Science",
    "section": "Assessments - Group presentations (35%)",
    "text": "Assessments - Group presentations (35%)\n\n\nYou will form groups prior to Reading Week\n\nPitch your ideas of API/datasets on Week 04\nForm the groups on Week 05\n\nGroup presentations:\n\nWeek 08 - worth 15% of final mark\nWeek 11 - worth 20% of final mark"
  },
  {
    "objectID": "slides/week01_slides_part1.html#assessments---final-project-40",
    "href": "slides/week01_slides_part1.html#assessments---final-project-40",
    "title": "DS105 Data for Data Science",
    "section": "Assessments - Final project (40%)",
    "text": "Assessments - Final project (40%)\n\n\nEach group will produce a webpage of their project\nDescription of data, research questions, challenges, statistics and simple plots\nThink of it as a portfolio project!\nSubmission deadline: Lent Term\n\nExact date to be confirmed\n(end of Jan/2023 - beginning of Feb/2023)"
  },
  {
    "objectID": "slides/week01_slides_part1.html#office-hours",
    "href": "slides/week01_slides_part1.html#office-hours",
    "title": "DS105 Data for Data Science",
    "section": "Office hours",
    "text": "Office hours\n\n\nIt is probably a good idea to book office hours if:\n\nyou struggled with a technical or theoretical aspect of a problem set in the previous week,\nyou have queries about careers in data science,\nyou want guidance in how to apply data science to other things you are studying outside this course.\n\nCome prepared. You only have 15 minutes.\nAsk for help sooner rather than later.\nBook slots via StudentHub up to 12 hours in advance."
  },
  {
    "objectID": "slides/week01_slides_part1.html#communication",
    "href": "slides/week01_slides_part1.html#communication",
    "title": "DS105 Data for Data Science",
    "section": "Communication",
    "text": "Communication\n\n\nJoin our Slack group (more info here)\nUse the public Slack channels to talk to share links, content (or memes) with your colleagues.\nOur teaching team will dedicate some time during the week to answer questions or other interactions on Slack.\nReserve üìß e-mail for formal requests: extensions, deferrals, etc.\n\nNo need to e-mail to inform you will skip a class, for example."
  },
  {
    "objectID": "slides/week01_slides_part1.html#any-questions",
    "href": "slides/week01_slides_part1.html#any-questions",
    "title": "DS105 Data for Data Science",
    "section": "Any questions?",
    "text": "Any questions?\n\n\n\n\n\n\nImage created with the DALL¬∑E algorithm using the prompt: ‚Äò35mm macro photography of a robot holding a question mark card, white background‚Äô"
  },
  {
    "objectID": "slides/week01_slides_part1.html#we-changed-how-we-consume-music",
    "href": "slides/week01_slides_part1.html#we-changed-how-we-consume-music",
    "title": "DS105 Data for Data Science",
    "section": "We changed how we consume music üéß",
    "text": "We changed how we consume music üéß\n\n\n\n\n\n\nTo interact with this plot, check reference (Fischer-Baum 2017) at the end of this presentation."
  },
  {
    "objectID": "slides/week01_slides_part1.html#we-changed-how-we-consume-video",
    "href": "slides/week01_slides_part1.html#we-changed-how-we-consume-video",
    "title": "DS105 Data for Data Science",
    "section": "We changed how we consume video üéûÔ∏è",
    "text": "We changed how we consume video üéûÔ∏è\n\n\n\n\n\n\nTo interact with this plot, check reference (Fischer-Baum 2017) at the end of this presentation."
  },
  {
    "objectID": "slides/week01_slides_part1.html#smartphones-are-a-very-recent-thing",
    "href": "slides/week01_slides_part1.html#smartphones-are-a-very-recent-thing",
    "title": "DS105 Data for Data Science",
    "section": "Smartphones üì± are a very recent thing",
    "text": "Smartphones üì± are a very recent thing\n\n\n\n\n\n\nTo interact with this plot, check reference (Fischer-Baum 2017) at the end of this presentation."
  },
  {
    "objectID": "slides/week01_slides_part1.html#we-spend-a-lot-more-time-connected",
    "href": "slides/week01_slides_part1.html#we-spend-a-lot-more-time-connected",
    "title": "DS105 Data for Data Science",
    "section": "We spend a lot more time connected",
    "text": "We spend a lot more time connected"
  },
  {
    "objectID": "slides/week01_slides_part1.html#references",
    "href": "slides/week01_slides_part1.html#references",
    "title": "DS105 Data for Data Science",
    "section": "References",
    "text": "References\n\n\nFischer-Baum, Reuben. 2017. ‚ÄúWhat ‚ÄòTech World‚Äô Did You Grow up In?‚Äù Washington Post. https://www.washingtonpost.com/graphics/2017/entertainment/tech-generations/.\n\n\nKolawole, Emi. 2013. ‚ÄúAbout Those 2005 and 2013 Photos of the Crowds in St. Peter‚Äôs Square.‚Äù Washington Post. http://wapo.st/WKKTMh.\n\n\n\n\n\nDS105 - Data for Data Science üñ•Ô∏è ü§π"
  },
  {
    "objectID": "slides/week01_slides_part2.html#data-science-is",
    "href": "slides/week01_slides_part2.html#data-science-is",
    "title": "üóìÔ∏è Week 01 - Part II  Data Science toolbox",
    "section": "Data science is‚Ä¶",
    "text": "Data science is‚Ä¶\n\n\n‚Äú[‚Ä¶] a field of study and practice that involves the collection, storage, and processing of data in order to derive important üí° insights into a problem or a phenomenon.\n\n\n\n\nSuch data may be generated by humans (surveys, logs, etc.) or machines (weather data, road vision, etc.),\n\n\n\n\nand could be in different formats (text, audio, video, augmented or virtual reality, etc.).‚Äù\n\n\n\n\n(Shah 2020, chap. 1) - Emphasis and emojis are of my own making."
  },
  {
    "objectID": "slides/week01_slides_part2.html#the-mythical-unicorn",
    "href": "slides/week01_slides_part2.html#the-mythical-unicorn",
    "title": "üóìÔ∏è Week 01 - Part II  Data Science toolbox",
    "section": "The mythical unicorn ü¶Ñ",
    "text": "The mythical unicorn ü¶Ñ\n\n\nknows everything about statistics\n\n\nable to communicate insights perfectly\n\n\nfully understands businesses like no one\n\n\nis a fluent computer programmer\n\n\n\nOf course, such a person does not exist!\n\n\nSee (Davenport 2020) for a more in-depth discussion about this"
  },
  {
    "objectID": "slides/week01_slides_part2.html#in-reality",
    "href": "slides/week01_slides_part2.html#in-reality",
    "title": "üóìÔ∏è Week 01 - Part II  Data Science toolbox",
    "section": "In reality‚Ä¶",
    "text": "In reality‚Ä¶\n\n\nWe are all jugglers ü§π\n\n\nEveryone brings a different skill set.\nWe need multi-disciplinary teams.\nGood data scientists know a bit of everything.\n\nNot fluent in all things\nUnderstands their strenghts and weaknessess\nThey know when and where to interface with others\n\n\n\n\n\n\n\n\n\nFind a good way to transition between these slides.\n\n\nSee (Schutt and O‚ÄôNeil 2013, chap. 1) for more on this."
  },
  {
    "objectID": "slides/week01_slides_part2.html#the-data-science-workflow-1",
    "href": "slides/week01_slides_part2.html#the-data-science-workflow-1",
    "title": "üóìÔ∏è Week 01 - Part II  Data Science toolbox",
    "section": "The Data Science Workflow",
    "text": "The Data Science Workflow\n\n\n\n\n\n   \n\nstart\n\n Start   \n\ngather\n\nGather data ¬†   \n\nstart->gather\n\n    \n\nstore\n\nStore it ¬†¬†¬†¬†¬†¬†¬†¬† somewhere   \n\ngather->store\n\n   ¬†¬†¬†¬†¬†   \n\nclean\n\nClean & ¬†¬†¬†¬†¬†¬†¬† pre-process   \n\nstore->clean\n\n   ¬†¬†¬†¬†¬†   \n\nbuild\n\nBuild a  dataset   \n\nclean->build\n\n   ¬†¬†¬†¬†¬†   \n\neda\n\nExploratory ¬†¬†¬† data analysis   \n\nbuild->eda\n\n    \n\nml\n\nMachine learning   \n\neda->ml\n\n   ¬†¬†¬†¬†¬†   \n\ninsight\n\nObtain ¬†¬† insights   \n\nml->insight\n\n   ¬†¬†¬†¬†¬†   \n\ncommunicate\n\nCommunicate results ¬†¬†¬†¬†¬†¬†¬†¬†   \n\ninsight->communicate\n\n   ¬†¬†¬†¬†¬†   \n\nend\n\n End   \n\ncommunicate->end\n\n   \n\n\n\n\n\n\n\n‚ö†Ô∏è Note that this is a simplified version of what happens in a data science project.  In practice, the process is not linear and there are many feedback loops."
  },
  {
    "objectID": "slides/week01_slides_part2.html#the-data-science-workflow-2",
    "href": "slides/week01_slides_part2.html#the-data-science-workflow-2",
    "title": "üóìÔ∏è Week 01 - Part II  Data Science toolbox",
    "section": "The Data Science Workflow",
    "text": "The Data Science Workflow\n\n\n\n\n\n   \n\nstart\n\n Start   \n\ngather\n\n Gather data ¬†   \n\nstart->gather\n\n    \n\nend\n\n End   \n\nstore\n\n Store it ¬†¬†¬†¬†¬†¬†¬†¬† somewhere   \n\ngather->store\n\n   ¬†¬†¬†¬†¬†   \n\nclean\n\n Clean & ¬†¬†¬†¬†¬†¬†¬† pre-process   \n\nstore->clean\n\n   ¬†¬†¬†¬†¬†   \n\nbuild\n\n Build a  dataset   \n\nclean->build\n\n   ¬†¬†¬†¬†¬†   \n\neda\n\n Exploratory ¬†¬†¬† data analysis   \n\nbuild->eda\n\n    \n\nml\n\n Machine learning   \n\neda->ml\n\n   ¬†¬†¬†¬†¬†   \n\ninsight\n\n Obtain ¬†¬† insights   \n\nml->insight\n\n   ¬†¬†¬†¬†¬†   \n\ncommunicate\n\n Communicate results ¬†¬†¬†¬†¬†¬†¬†¬†   \n\ninsight->communicate\n\n   ¬†¬†¬†¬†¬†   \n\ncommunicate->end\n\n   \n\n\n\n\n\nIt is often said that 80% of the time and effort spent on a data science project goes to the tasks highlighted above."
  },
  {
    "objectID": "slides/week01_slides_part2.html#the-data-science-workflow-3",
    "href": "slides/week01_slides_part2.html#the-data-science-workflow-3",
    "title": "üóìÔ∏è Week 01 - Part II  Data Science toolbox",
    "section": "The Data Science Workflow",
    "text": "The Data Science Workflow\n\n\n\n\n\n   \n\nstart\n\n Start   \n\ngather\n\n Gather data ¬†   \n\nstart->gather\n\n    \n\nend\n\n End   \n\nstore\n\n Store it ¬†¬†¬†¬†¬†¬†¬†¬† somewhere   \n\ngather->store\n\n   ¬†¬†¬†¬†¬†   \n\nclean\n\n Clean & ¬†¬†¬†¬†¬†¬†¬† pre-process   \n\nstore->clean\n\n   ¬†¬†¬†¬†¬†   \n\nbuild\n\n Build a  dataset   \n\nclean->build\n\n   ¬†¬†¬†¬†¬†   \n\neda\n\n Exploratory ¬†¬†¬† data analysis   \n\nbuild->eda\n\n    \n\neda->end\n\n    \n\nml\n\n Machine learning   \n\neda->ml\n\n   ¬†¬†¬†¬†¬†   \n\ninsight\n\n Obtain ¬†¬† insights   \n\nml->insight\n\n   ¬†¬†¬†¬†¬†   \n\ncommunicate\n\n Communicate results ¬†¬†¬†¬†¬†¬†¬†¬†   \n\ninsight->communicate\n\n   ¬†¬†¬†¬†¬†  \n\n\n\n\n\nAnd this is what this course is about! You will learn some of the most common tools used during this process."
  },
  {
    "objectID": "slides/week01_slides_part2.html#python-vs-r",
    "href": "slides/week01_slides_part2.html#python-vs-r",
    "title": "üóìÔ∏è Week 01 - Part II  Data Science toolbox",
    "section": "Python vs R",
    "text": "Python vs R\n\n\n Python\n\nPull data from webpages & APIs:\n\nselenium*, scrapy, requests*\n\nReshape data\n\npandas*, numpy, scipy\n\nPlotting data\n\nmatplotlib, plotnine*, altair\n\nShare & Report\n\nGithub Markdown*\nJupyter*\n\n\n\n\n\nPull data from webpages & APIs:\n\nRSelenium, httr, rvest\n\nReshape data\n\ntidyverse (all packages)\n\nPlotting data\n\nggplot*\n\nShare & Report\n\nGithub Markdown*\nRMarkdown, knitr, Quarto*\n\n\n\n\n\n\n\n* In this course I will focus on these packages, but the principles shouldn‚Äôt change much if you decide to use other libraries or programming language."
  },
  {
    "objectID": "slides/week01_slides_part2.html#how-should-we-share-code",
    "href": "slides/week01_slides_part2.html#how-should-we-share-code",
    "title": "üóìÔ∏è Week 01 - Part II  Data Science toolbox",
    "section": "How should we share code?",
    "text": "How should we share code?\n\n\n\n\n\n\nGithub!\n\n\nUse  Github for everything related to your project!\n\nYou will learn to setup Github for your own code on üóìÔ∏è Week 05‚Äôs lab.\nYou will learn how to work effectively as a team on Github on üóìÔ∏è Week 09‚Äôs lab.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\nDon‚Äôt share code via e-mail, Dropbox, Google Drive or anything like that!\nIt is a bad practice as things get messy very quickly.\n\n\n\n\n\nRemember that you have some time to develop your projects."
  },
  {
    "objectID": "slides/week01_slides_part2.html#where-do-i-get-data",
    "href": "slides/week01_slides_part2.html#where-do-i-get-data",
    "title": "üóìÔ∏è Week 01 - Part II  Data Science toolbox",
    "section": "Where do I get data?",
    "text": "Where do I get data?\n\n\n\n Twitter API\n Reddit API\n Tiktok API\n Instagram API\n\n\n\n Spotify API\n New York Times API\n The Guardian API\n Weather.gov API\n\n\n\n\n\n\n\n\n\nTip: Data is Plural\n\n\nData is Plural run by Buzzfeed‚Äôs data editor üßë Jeremy Singer-Vine. People send him interesting/funny/odd datasets and he shares them in a weekly newsletter. Here‚Äôs the link to the website (the google doc list of datasets is linked here)"
  },
  {
    "objectID": "slides/week01_slides_part2.html#references",
    "href": "slides/week01_slides_part2.html#references",
    "title": "üóìÔ∏è Week 01 - Part II  Data Science toolbox",
    "section": "References",
    "text": "References\n\n\nDavenport, Thomas. 2020. ‚ÄúBeyond Unicorns: Educating, Classifying, and Certifying Business Data Scientists.‚Äù Harvard Data Science Review 2 (2). https://doi.org/10.1162/99608f92.55546b4a.\n\n\nSchutt, Rachel, and Cathy O‚ÄôNeil. 2013. Doing Data Science. First edition. Beijing ; Sebastopol: O‚ÄôReilly Media. https://ebookcentral.proquest.com/lib/londonschoolecons/detail.action?docID=1465965.\n\n\nShah, Chirag. 2020. A Hands-on Introduction to Data Science. Cambridge, United Kingdom ; New York, NY, USA: Cambridge University Press. https://librarysearch.lse.ac.uk/permalink/f/1n2k4al/TN_cdi_askewsholts_vlebooks_9781108673907.\n\n\n\n\n\nDS105 - Data for Data Science üñ•Ô∏è ü§π"
  },
  {
    "objectID": "slides/week02_slides_part1.html#what-operating-systems-os-do",
    "href": "slides/week02_slides_part1.html#what-operating-systems-os-do",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "What Operating Systems (OS) do",
    "text": "What Operating Systems (OS) do\n\n\n\n\nA computer can be divided in four parts:\n\nhardware ‚Äî provides the basic computing resources for the system\napplication programs ‚Äî define the ways in which these resources are used\noperating system ‚Äî controls the hardware and coordinates its use among the various application programs for the various users\nuser ‚Äî a person or a bot (a computer script) that requests actions from the computer.\n\n\n\n\n\n\n\n\n\n\n   \n\nuser\n\n User   \n\napp\n\n Application Programs (compilers, web browsers, development kits, etc.)   \n\nuser->app\n\n     \n\nos\n\n Operating System   \n\napp->os\n\n     \n\nhardware\n\n Computer Hardware (CPU, memory, I/O devices, etc.)   \n\nos->hardware\n\n    \n\n\n\n\n\n\n\n\n\nFor more details, check (Silberschatz, Galvin, and Gagne 2005, chap. 1)"
  },
  {
    "objectID": "slides/week02_slides_part1.html#insight-into-operating-systems",
    "href": "slides/week02_slides_part1.html#insight-into-operating-systems",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "Insight into operating systems",
    "text": "Insight into operating systems\n\n\n‚ÄúAn operating system is similar to a government. Like a government, it performs no useful function by itself. It simply provides an environment within which other programs can do userful work.‚Äù\n\n\n‚Äì (Silberschatz, Galvin, and Gagne 2005, chap. 1)\n\n\n\n\nIf this sounds a bit vague to you, it is because it is!\nIt is difficult to specify which programs are part of the OS and which ones are not.\nLet‚Äôs try to define what an OS is anyways ‚è≠Ô∏è"
  },
  {
    "objectID": "slides/week02_slides_part1.html#definition-of-os",
    "href": "slides/week02_slides_part1.html#definition-of-os",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "Definition of OS",
    "text": "Definition of OS\n\n\n‚ÄúThe OS is the one programming running at all times on the computer‚Äù\n\nThis is usually also called the kernel\n\nThere are also other type of programs who might be running alongside.\n\nFor example, the  Terminal (more on that in a minute)\n\nüì± Mobile computers usually has a lot more ‚Äúadditional‚Äù software running alongside the kernel. We call it the middleware.\n\nThese applications support things like: multimedia, graphics, internal app databases."
  },
  {
    "objectID": "slides/week02_slides_part1.html#why-bother-with-this",
    "href": "slides/week02_slides_part1.html#why-bother-with-this",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "Why bother with this?",
    "text": "Why bother with this?\n\n\n\n\nIt is improbable you will ever need to interact with the kernel directly.\nBut, we often need to install custom software to perform some data analysis\n\nThis software might not come from Apple or Microsoft Store.\nThose are things you have to install ‚Äúmanually‚Äù\n\n\n\n\n\n\n\n\n\n\nTip\n\n\nWhen that happens, you might encounter error messages that make no sense if you don‚Äôt understand a little of how everything is tied together.\n\n\n\n\n\n\n\n\n\nImage created with the DALL¬∑E algorithm using the prompt: ‚Äòa gigantic wooden question mark looms above the big ben, ultra realistic awesome painting‚Äô ü§ì"
  },
  {
    "objectID": "slides/week02_slides_part1.html#history",
    "href": "slides/week02_slides_part1.html#history",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "History",
    "text": "History\n\n\n\n\nIn the early days of modern computing, back when computers were not accessible to everyone, software (applications) generally came with the open source code.\nYou could read precisely which instructions the computer would follow when running the software.\nAs the industry grew, most software companies released only the binaries ‚Äî a type of file you can only execute, not read as if it was a text.\n\nThis includes Operating Systems! ‚è≠Ô∏è\n\n\n\n\n\n\n\nA computer from the 1950s.(Computer History Museum n.d.)"
  },
  {
    "objectID": "slides/week02_slides_part1.html#unix",
    "href": "slides/week02_slides_part1.html#unix",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "UNIX",
    "text": "UNIX\n\n\n\n\nUNIX was the first big Operating System, developed at Bell Labs and AT&T\nIt aimed to be simple* and easy to port to any hardware architecture\nBut it required a license\nIn the late 1980s and early 1990s, a group of hackers and activists developed free & open source alternatives to UNIX.\n\n\n\n\n\n\nHow the UNIX System III looks like.\n\n\n\n\n\n\nSource: Wikimedia Commons - Rwoodsmall\n\n\n\n* As simple as these things get."
  },
  {
    "objectID": "slides/week02_slides_part1.html#gnulinux",
    "href": "slides/week02_slides_part1.html#gnulinux",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "GNU/Linux",
    "text": "GNU/Linux\n\n\n\n\nThis led to the birth of one of the most influential operating systems: GNU/Linux, or simply Linux.\n\n\n\n\n Android, the most popular OS for phones worldwide, is based on Linux.\n\n\n\n\n\nTwo people were instrumental to the development of Linux\n\nRichard Stallman\nLinus Torvalds\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nGNU stands for ‚ÄúGNU is not Unix‚Äù. Yes, it is recursive."
  },
  {
    "objectID": "slides/week02_slides_part1.html#macos",
    "href": "slides/week02_slides_part1.html#macos",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "macOS",
    "text": "macOS\n\n\nmacOS is the Operating System of Apple computers\nIt is a hybrid system. It has a free open source component called Darwin, but it includes proprietary, closed-source components as well.\niOS, Apple‚Äôs mobile operating system, is also based on Darwin\nDarwin itself is based on BDS UNIX, a derivative of the original UNIX system."
  },
  {
    "objectID": "slides/week02_slides_part1.html#windows",
    "href": "slides/week02_slides_part1.html#windows",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "Windows",
    "text": "Windows\n\nWindows has its own history.\nIts predecessor, OS/2 operating system was co-developed by Microsoft and IBM.\nBut then, Microsoft took on its own path and developed its own versions of the OS: Windows NT, Windows 95, Windows 98, Windows 2000, Windows XP, Windows 7, Windows Vista*, etc.\nWindows popularity can be traced to the success of the Office suite\n\n\n\n\nSee (Silberschatz, Galvin, and Gagne 2005, Appendix B) for more on Windows."
  },
  {
    "objectID": "slides/week02_slides_part1.html#emulators-virtual-machines",
    "href": "slides/week02_slides_part1.html#emulators-virtual-machines",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "Emulators & Virtual Machines",
    "text": "Emulators & Virtual Machines\n\n\n\n\nYou can install an emulator to run Windows inside Mac (and vice-versa)\n\nProvided you own a licence to install the other OS\n\n\n\n\n\nYou can share files to and from the virtual machine inside the emulator, but the internal machine will ‚Äúthink‚Äù it is a separate computer.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn the üñ•Ô∏è labs on üóìÔ∏è Week 03, you will access a virtual machine that lives in the cloud\n\n\n\n\n\n\n\n\nExample of commercial virtualization softwares"
  },
  {
    "objectID": "slides/week02_slides_part1.html#windows-subsystem-for-linux-wsl",
    "href": "slides/week02_slides_part1.html#windows-subsystem-for-linux-wsl",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "Windows Subsystem for Linux (WSL)",
    "text": "Windows Subsystem for Linux (WSL)\n\n\nIn an attempt to entice Linux users (especially developers), Microsoft added a Linux emulator to Windows named ‚ÄúWindows Subsystem for Linux‚Äù\n\n\n\n\nYou install your preferred Linux distribution\n\nUbuntu is one of the most popular\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nOur üñ•Ô∏è labs on Weeks 2 & 3 will focus on Linux/UNIX-like commands.\nWindows users will have to install WSL on their computers."
  },
  {
    "objectID": "slides/week02_slides_part1.html#shell",
    "href": "slides/week02_slides_part1.html#shell",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "Shell",
    "text": "Shell\n\n\nTypically, the terminal runs a program (app) called the shell.\nThe shell awaits, interprets, processes, executes, and responds to commands typed in by the user.\nThere are many shells, each has its own features.\nPopular Linux shells:\n\nsh or the Bourne shell: developed at AT&T labs in the 70s by a guy named Stephen Bourne.\nbash or the Bourne again shell: very popular, compatible with sh shell scripts.\n\nOur üñ•Ô∏è labs will focus on bash\n\nksh or the Korn shell: provides enhancements over the sh and it is also compatible with bash.\ncsh and tcsh: shells that have a syntax similar to the programming language C.\n\n\n\n\nWant to become a pro at shell scripting? Check out (Ebrahim and Mallett 2018)."
  },
  {
    "objectID": "slides/week02_slides_part1.html#windows-cmd-vs-powershell",
    "href": "slides/week02_slides_part1.html#windows-cmd-vs-powershell",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "Windows CMD vs PowerShell",
    "text": "Windows CMD vs PowerShell\n\nAs mentioned before, Windows has its own thing.\nThere are two main terminals/shells on Windows these days\n\n\n\nCMD\n\nPowershell\n\n\n\n\n\nOriginal product: Microsoft. This animation: Useerup, CC BY-SA 3.0, via Wikimedia Commons"
  },
  {
    "objectID": "slides/week02_slides_part1.html#what-are-files",
    "href": "slides/week02_slides_part1.html#what-are-files",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "What are files?",
    "text": "What are files?\n\n\n\n\n\n\nUltimately, everything in a computer is just a bunch of 0s and 1s\nFiles are a set of conventions that allows us to extract information from them.\nLet‚Äôs see where these ideas come from ‚è≠Ô∏è\n\n\n\nImage created with the DALL¬∑E algorithm using the prompt: ‚Äò35mm macro photography of a robot holding a question mark card, white background‚Äô"
  },
  {
    "objectID": "slides/week02_slides_part1.html#structured-data-index-cards",
    "href": "slides/week02_slides_part1.html#structured-data-index-cards",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "Structured data: Index cards",
    "text": "Structured data: Index cards\n\nOrigins in the 19th century, with botanist Carl Linnaeus, who needed to record species that he was studying\nThis was a form of database\n\neach piece of information about a species formed a field\neach species‚Äô entry in the system formed a record\nthe records were indexed using some reference system"
  },
  {
    "objectID": "slides/week02_slides_part1.html#heyday-use-in-libraries-to-catalog-books",
    "href": "slides/week02_slides_part1.html#heyday-use-in-libraries-to-catalog-books",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "Heyday: Use in libraries to catalog books",
    "text": "Heyday: Use in libraries to catalog books"
  },
  {
    "objectID": "slides/week02_slides_part1.html#a-record-looked-like-this",
    "href": "slides/week02_slides_part1.html#a-record-looked-like-this",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "A record looked like this",
    "text": "A record looked like this"
  },
  {
    "objectID": "slides/week02_slides_part1.html#dewey-decimal-system",
    "href": "slides/week02_slides_part1.html#dewey-decimal-system",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "Dewey decimal system",
    "text": "Dewey decimal system\n\n\na proprietary library classification system first published in the United States by Melvil Dewey in 1876\nscheme is made up of ten classes, each divided into ten divisions, each having ten sections\nthe system‚Äôs notation uses Arabic numbers, with three whole numbers making up the main classes and sub-classes and decimals creating further divisions\n\n\n\n\nExample:\n500 Natural sciences and mathematics\n    510 Mathematics\n        516 Geometry\n            516.3 Analytic geometries\n                516.37 Metric differential geometries\n                    516.375 Finsler Geometry"
  },
  {
    "objectID": "slides/week02_slides_part1.html#hierarchical-directory-structure",
    "href": "slides/week02_slides_part1.html#hierarchical-directory-structure",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "Hierarchical directory structure",
    "text": "Hierarchical directory structure\n\n\n\n\nThis kind of hierarchical structure is still present in all modern OSes\nA directory, or folder, is a place where many files are stored\nIn theory, it can contain infinite sub-directories and files"
  },
  {
    "objectID": "slides/week02_slides_part1.html#unix-directory-tree",
    "href": "slides/week02_slides_part1.html#unix-directory-tree",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "UNIX directory tree",
    "text": "UNIX directory tree\n\n\n\n\n\n   \n\nroot\n\n /   \n\nbin\n\n bin   \n\nroot->bin\n\n    \n\ndev\n\n dev   \n\nroot->dev\n\n    \n\netc\n\n etc   \n\nroot->etc\n\n    \n\nhome\n\n home   \n\nroot->home\n\n    \n\nlib\n\n lib   \n\nroot->lib\n\n    \n\nmnt\n\n mnt   \n\nroot->mnt\n\n    \n\nproc\n\n proc   \n\nroot->proc\n\n    \n\nnamedroot\n\n root   \n\nroot->namedroot\n\n    \n\nsbin\n\n sbin   \n\nroot->sbin\n\n    \n\ntmp\n\n tmp   \n\nroot->tmp\n\n    \n\nusr\n\n usr   \n\nroot->usr\n\n    \n\nvar\n\n var   \n\nroot->var\n\n    \n\njonathan\n\n jonathan   \n\nhome->jonathan\n\n    \n\ndocuments\n\n Documents   \n\njonathan->documents\n\n    \n\nimages\n\n Images   \n\njonathan->images\n\n    \n\nvideos\n\n Videos   \n\njonathan->videos\n\n    \n\ndownloads\n\n Downloads   \n\njonathan->downloads\n\n    \n\nworkspace\n\n Workspace   \n\ndocuments->workspace\n\n    \n\nds105\n\n lse-ds105-course-notes   \n\nworkspace->ds105\n\n    \n\nusr_lib\n\n lib   \n\nusr->usr_lib\n\n    \n\nusr_bin\n\n bin   \n\nusr->usr_bin\n\n    \n\nusr_include\n\n include   \n\nusr->usr_include\n\n    \n\nvar_log\n\n log   \n\nvar->var_log\n\n    \n\nvar_mail\n\n mail   \n\nvar->var_mail\n\n    \n\nvar_spool\n\n spool   \n\nvar->var_spool\n\n    \n\nvar_tmp\n\n tmp   \n\nvar->var_tmp\n\n   \n\n\n\n\n\n\nCheck out this webpage for a description of what each directory represents"
  },
  {
    "objectID": "slides/week02_slides_part1.html#references",
    "href": "slides/week02_slides_part1.html#references",
    "title": "üóìÔ∏è Week 02 Operating Systems, Files & The Terminal",
    "section": "References",
    "text": "References\n\n\nComputer History Museum. n.d. ‚Äú1950  Timeline of Computer History.‚Äù 1950  Timeline of Computer History. Accessed September 16, 2022. https://www.computerhistory.org/timeline/1950/.\n\n\nEbrahim, Mokhtar, and Andrew Mallett. 2018. Mastering Linux Shell Scripting: A Practical Guide to Linux Command-Line, Bash Scripting, and Shell Programming, 2nd Edition. 2nd ed. Birmingham: Packt Publishing.\n\n\nPelz, Oliver. 2018. Fundamentals of Linux: Explore the Essentials of the Linux Command Line. Birmingham: Packt Publishing Ltd.\n\n\nSilberschatz, Abraham, Peter B. Galvin, and Greg Gagne. 2005. Operating System Concepts. 7th ed. Hoboken, NJ: J. Wiley & Sons.\n\n\n\n\n\nDS105 - Data for Data Science üñ•Ô∏è ü§π"
  }
]